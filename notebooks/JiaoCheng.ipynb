{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15/02/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JiaoCheng:\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('JiaoCheng Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.feature_n_ningxiang_score_dict = None\n",
    "        self.feature_combo_n_index_map = None\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self._up_to = 0\n",
    "        self._tune_features = False\n",
    "        self._seed = 19421221\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.combos = None\n",
    "        self.n_items = None\n",
    "        self.outmost_layer = None\n",
    "        self._core = None\n",
    "        self._relative_combos = None\n",
    "        self._both_combos = None\n",
    "        self._dealt_with = None\n",
    "        self._pos_neg_combos = None\n",
    "        self._abs_max = None\n",
    "        self._new_combos = None\n",
    "        self.parameter_value_map_index = None\n",
    "        self._total_combos = None\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "        \n",
    "\n",
    "    def read_in_data(self, train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.train_x = train_x\n",
    "        print(\"Read in Train X data\")\n",
    "\n",
    "        self.train_y = train_y\n",
    "        print(\"Read in Train x data\")\n",
    "\n",
    "        self.val_x = val_x\n",
    "        print(\"Read in Val X data\")\n",
    "\n",
    "        self.val_y = val_y\n",
    "        print(\"Read in Val y data\")\n",
    "\n",
    "        self.test_x = test_x\n",
    "        print(\"Read in Test X data\")\n",
    "\n",
    "        self.test_y = test_y\n",
    "        print(\"Read in Test y data\")\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self._sort_hyperparameter_choices()\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        if self._tune_features == True:\n",
    "            tune_result_columns.append('feature combo ningxiang score')\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "\n",
    "    def set_non_tuneable_hyperparameters(self, non_tuneable_hyperparameter_choice):\n",
    "        \"\"\" Input Non tuneable hyperparameter choice \"\"\"\n",
    "\n",
    "        if type(non_tuneable_hyperparameter_choice) is not dict:\n",
    "            print('non_tuneable_hyeprparameters_choice must be dict, please try again')\n",
    "            return\n",
    "        \n",
    "        for nthp in non_tuneable_hyperparameter_choice:\n",
    "            if type(non_tuneable_hyperparameter_choice[nthp]) in (set, list, tuple, dict):\n",
    "                print('non_tuneable_hyperparameters_choice must not be of array-like type')\n",
    "                return\n",
    "\n",
    "        self.non_tuneable_parameter_choices = non_tuneable_hyperparameter_choice\n",
    "\n",
    "        print(\"Successfully recorded non_tuneable_hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def set_features(self, ningxiang_output):\n",
    "        \"\"\" Input features \"\"\"\n",
    "\n",
    "        if type(ningxiang_output) is not dict:\n",
    "            print(\"Please ensure NingXiang output is a dict\")\n",
    "            return\n",
    "        \n",
    "        if not self.combos:\n",
    "            print(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            return\n",
    "        \n",
    "        # sort ningxiang just for safety, and store up\n",
    "        ningxiang_output_sorted = self._sort_features(ningxiang_output)\n",
    "        self.feature_n_ningxiang_score_dict = ningxiang_output_sorted\n",
    "\n",
    "        # activate this switch\n",
    "        self._tune_features = True\n",
    "\n",
    "        # update previous internal structures based on first set of hyperparameter choices\n",
    "        ##here used numbers instead of tuples as the values in parameter_choices; thus need another mapping to get map back to the features\n",
    "        self.parameter_choices['features'] = tuple([i for i in range(len(ningxiang_output_sorted))])\n",
    "        self.feature_combo_n_index_map = {i: ningxiang_output_sorted.keys()[i] for i in range(len(ningxiang_output_sorted))}\n",
    "\n",
    "        self.hyperparameters = list(self.parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(self.parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_combinations()\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded tuneable feature combination choices and updated relevant internal structures\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_features(self, ningxiang_output):\n",
    "        \"\"\" Helper for sorting features based on NingXiang values (input dict output dict) \"\"\"\n",
    "\n",
    "        ningxiang_output_list = [(key, ningxiang_output[key]) for key in ningxiang_output]\n",
    "\n",
    "        ningxiang_output_list.sort(key = lambda x:x[1])\n",
    "\n",
    "        ningxiang_output_sorted = {x[0]:x[1] for x in ningxiang_output_list}\n",
    "\n",
    "        return ningxiang_output_sorted\n",
    "\n",
    "\n",
    "    \n",
    "    def set_tuning_order(self, order):\n",
    "        \"\"\" Input sorting order \"\"\"\n",
    "        \n",
    "        if type(order) is not list:\n",
    "            print(\"order must be a list, please try agian\")\n",
    "            return\n",
    "        \n",
    "        if self.hyperparameters == False:\n",
    "            print('Please run set_hyperparameters() first')\n",
    "            return\n",
    "        \n",
    "        if 'features' in self.hyperparameters:\n",
    "            if self._tune_features == False:\n",
    "                print('Please run set_features() first')\n",
    "                return\n",
    "        \n",
    "        for hp in order:\n",
    "            if hp not in self.hyperparameter:\n",
    "                print(f'Feature {hp} is not in self.hyperparameter which was set by set_hyperparameters(); consider reinitiating JiaoCheng or double checking input')\n",
    "                return\n",
    "\n",
    "        self.hyperparameter_tuning_order = order\n",
    "        self.tuning_order_map_hp = {order[i]:i for i in range(len(order))}\n",
    "    \n",
    "\n",
    "    \n",
    "    def set_hyperparameter_default_values(self, default_values):\n",
    "        \"\"\" Input default values for hyperparameters \"\"\"\n",
    "\n",
    "        if type(default_values) is not dict:\n",
    "            print(\"default_values must be a dict, please try agian\")\n",
    "            return\n",
    "        \n",
    "        if self.hyperparameters == False:\n",
    "            print('Please run set_hyperparameters() first')\n",
    "            return\n",
    "        \n",
    "        if 'features' in self.hyperparameters:\n",
    "            if self._tune_features == False:\n",
    "                print('Please run set_features() first')\n",
    "                return\n",
    "        \n",
    "        for hp in default_values:\n",
    "            if hp not in self.hyperparameter:\n",
    "                print(f'Feature {hp} is not in self.hyperparameter which was set by set_hyperparameters(); consider reinitiating JiaoCheng or double checking input')\n",
    "                return\n",
    "            if default_values[hp] not in self.parameter_choices[hp]:\n",
    "                print(f'{default_values[hp]} is not a value to try out in self.hyperparameter which was set by set_hyperparameters(). consider reinitiating JiaoCheng or double checking input')\n",
    "                return\n",
    "\n",
    "        self.hyperparameter_default_values = default_values\n",
    "\n",
    "\n",
    "        \n",
    "    def tune(self, key_stats_only = False): #TODO\n",
    "        \"\"\" Begin tuning \"\"\"\n",
    "\n",
    "        if self.train_x is None or self.train_y is None or self.val_x is None or self.val_y is None or self.test_x is None or self.test_y is None:\n",
    "            print(\" Missing one of the datasets, please run .read_in_data() \")\n",
    "            return\n",
    "\n",
    "        if self.model is None:\n",
    "            print(\" Missing model, please run .read_in_model() \")\n",
    "            return\n",
    "        \n",
    "        if self.combos is None:\n",
    "            print(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            return\n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            print(\"Missing tuning result csv saving address, please run ._save_tuning_result() first\")\n",
    "\n",
    "        self.key_stats_only = key_stats_only\n",
    "        \n",
    "        \n",
    "        starting_hp_combo = [val for val in self.hyperparameter_default_values] # setup starting combination\n",
    "\n",
    "        round = 1\n",
    "        switch = 1 # continuously loop through features until converge (combo stays same after a full round)\n",
    "        while switch:\n",
    "            print(\"ROUND\", round)\n",
    "            round += 1\n",
    "\n",
    "            # first store previous round's best combo/the starting combo before each round; for comparison at the end\n",
    "            old_starting_hp_combo = copy.deepcopy(starting_hp_combo)\n",
    "\n",
    "            for i in range(len(self.hyperparameter_tuning_order)): # tune each hp in order\n",
    "                print(self.hyperparameter_tuning_order[i])\n",
    "\n",
    "                combo = copy.deepcopy(starting_hp_combo) # tune the root combo\n",
    "                if not self.checked[(tuple(combo))]:\n",
    "                    self._up_to += 1\n",
    "                    self._train_and_test_combo(combo)\n",
    "                else:\n",
    "                    print(f'Already Trained and Tested combination {self._up_to}')\n",
    "\n",
    "                j = 0\n",
    "                continuing = 1\n",
    "                while continuing: # search out all values of this hyperparameter\n",
    "                    j += 1 # distance to move away from the root combo\n",
    "                    \n",
    "                    tmp_switch = 0\n",
    "\n",
    "                    combo = copy.deepcopy(starting_hp_combo)\n",
    "                    if combo[self.tuning_order_map_hp[i]] + j < self.n_items[self.tuning_order_map_hp[i]]: # check upward movement hasn't exceeded bound\n",
    "                        combo[self.tuning_order_map_hp[i]] += j\n",
    "                        \n",
    "                        if not self.checked[(tuple(combo))]:\n",
    "                            self._up_to += 1\n",
    "                            self._train_and_test_combo(combo)\n",
    "                        else:\n",
    "                            print(f'Already Trained and Tested combination {self._up_to}')\n",
    "\n",
    "                    else:\n",
    "                        tmp_switch += 1 \n",
    "                    \n",
    "\n",
    "                    if combo[self.tuning_order_map_hp[i]] - j >= 0: # check downward movement hasn't exceeded bound\n",
    "                        combo[self.tuning_order_map_hp[i]] -= j\n",
    "                        \n",
    "                        if not self.checked[(tuple(combo))]:\n",
    "                            self._up_to += 1\n",
    "                            self._train_and_test_combo(combo)\n",
    "                        else:\n",
    "                            print(f'Already Trained and Tested combination {self._up_to}')\n",
    "\n",
    "                    else:\n",
    "                        tmp_switch += 1\n",
    "\n",
    "                    \n",
    "                    if tmp_switch == 2: # if both have exceeded bound then stop\n",
    "                        continuing = 0\n",
    "                        \n",
    "                starting_hp_combo = copy.deepcopy(self.best_combo) # take the best combo after this hyperparameter has been tuned\n",
    "            \n",
    "            if starting_hp_combo == old_starting_hp_combo: # if after this full round best combo hasn't moved, then can terminate\n",
    "                switch = 0\n",
    "        \n",
    "\n",
    "        # Display final information\n",
    "        print(\"TUNING FINISHED\\n\")\n",
    "\n",
    "        print('Max Score: \\n', self.best_score)\n",
    "        print('Max Combo: \\n', self.best_combo)\n",
    "\n",
    "        print('% Combos Checked:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "        \n",
    "        \n",
    "        if self._tune_features == True:\n",
    "            del params['features']\n",
    "            tmp_train_x = self.train_x[list(self.feature_combo_n_index_map[combo[-1]])] \n",
    "            tmp_val_x = self.val_x[list(self.feature_combo_n_index_map[combo[-1]])]\n",
    "            tmp_test_x = self.test_x[list(self.feature_combo_n_index_map[combo[-1]])]\n",
    "\n",
    "            # add non tuneable parameters\n",
    "            for nthp in self.non_tuneable_parameter_choices:\n",
    "                params[nthp] = self.non_tuneable_parameter_choices[nthp]\n",
    "\n",
    "            # initialise object\n",
    "            clf = self.model(**params)\n",
    "\n",
    "            params['features'] = [list(self.feature_combo_n_index_map[combo[-1]])] \n",
    "            params['feature combo ningxiang score'] = self.feature_n_ningxiang_score_dict[self.feature_combo_n_index_map[combo[-1]]]\n",
    "\n",
    "        else:\n",
    "            tmp_train_x = self.train_x\n",
    "            tmp_val_x = self.val_x\n",
    "            tmp_test_x = self.test_x\n",
    "\n",
    "            # add non tuneable parameters\n",
    "            for nthp in self.non_tuneable_parameter_choices:\n",
    "                params[nthp] = self.non_tuneable_parameter_choices[nthp]\n",
    "\n",
    "            # initialise object\n",
    "            clf = self.model(**params)\n",
    "\n",
    "        # get time and fit\n",
    "        start = time.time()\n",
    "        clf.fit(tmp_train_x, self.train_y)\n",
    "        end = time.time()\n",
    "\n",
    "        # get predicted labels/values for three datasets\n",
    "        train_pred = clf.predict(tmp_train_x)\n",
    "        val_pred = clf.predict(tmp_val_x)\n",
    "        test_pred = clf.predict(tmp_test_x)\n",
    "\n",
    "        # get scores and time used\n",
    "        time_used = end-start\n",
    "\n",
    "        # build output dictionary and save result\n",
    "        df_building_dict = params\n",
    "        for nthp in self.non_tuneable_parameter_choices:\n",
    "            del params[nthp] \n",
    "\n",
    "\n",
    "        if self.clf_type == 'Regression':\n",
    "\n",
    "            train_score = val_score = test_score = train_rmse = val_rmse = test_rmse = train_mape = val_mape = test_mape = 0\n",
    "\n",
    "            try:\n",
    "                train_score = r2_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = r2_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = r2_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if self.key_stats_only == False:\n",
    "                try:\n",
    "                    train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            df_building_dict['Train r2'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val r2'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test r2'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train RMSE'] = [np.round(train_rmse, 6)]\n",
    "            df_building_dict['Val RMSE'] = [np.round(val_rmse, 6)]\n",
    "            df_building_dict['Test RMSE'] = [np.round(test_rmse, 6)]\n",
    "            \n",
    "            if self.key_stats_only == False:\n",
    "                df_building_dict['Train MAPE'] = [np.round(train_mape, 6)]\n",
    "                df_building_dict['Val MAPE'] = [np.round(val_mape, 6)]\n",
    "                df_building_dict['Test MAPE'] = [np.round(test_mape, 6)]\n",
    "\n",
    "        \n",
    "        elif self.clf_type == 'Classification':\n",
    "\n",
    "            train_score = val_score = test_score = train_bal_accu = val_bal_accu = test_bal_accu = train_f1 = val_f1 = test_f1 = \\\n",
    "                train_precision = val_precision = test_precision = train_recall = val_recall = test_recall = 0\n",
    "\n",
    "            try:    \n",
    "                train_score = accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            df_building_dict['Train accu'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val accu'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test accu'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 6)]\n",
    "            df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 6)]\n",
    "            df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 6)]\n",
    "            df_building_dict['Train f1'] = [np.round(train_f1, 6)]\n",
    "            df_building_dict['Val f1'] = [np.round(val_f1, 6)]\n",
    "            df_building_dict['Test f1'] = [np.round(test_f1, 6)]\n",
    "            df_building_dict['Train precision'] = [np.round(train_precision, 6)]\n",
    "            df_building_dict['Val precision'] = [np.round(val_precision, 6)]\n",
    "            df_building_dict['Test precision'] = [np.round(test_precision, 6)]\n",
    "            df_building_dict['Train recall'] = [np.round(train_recall, 6)]\n",
    "            df_building_dict['Val recall'] = [np.round(val_recall, 6)]\n",
    "            df_building_dict['Test recall'] = [np.round(test_recall, 6)]\n",
    "\n",
    "\n",
    "        df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "\n",
    "        tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "\n",
    "        self.tuning_result = self.tuning_result.append(tmp)\n",
    "        self._save_tuning_result()\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_clf = clf\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "        print(f'''Trained and Tested combination {self._up_to} of {self._total_combos}: {combo}, taking {time_used} seconds to get val score of {val_score}\n",
    "        Current best combo: {self.best_combo} with val score {self.best_score}''')\n",
    "\n",
    "\n",
    "\n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        tuning_result_saving_address_strip = self.tuning_result_saving_address.split('.csv')[0]\n",
    "\n",
    "        self.tuning_result.to_csv(f'{tuning_result_saving_address_strip}.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print(f'(Current) Best combo: {self.best_combo} with val score {self.best_score}')\n",
    "\n",
    "    \n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            print(\"Missing parameter_choices to build parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            print('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "        self._up_to = 0\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of JiaoCheng\n",
    "        for row in self.tuning_result.iterrows():\n",
    "\n",
    "            self._up_to += 1\n",
    "    \n",
    "            combo = tuple([self.parameter_value_map_index[hyperparam][row[1][hyperparam]] for hyperparam in self.hyperparameters])\n",
    "            \n",
    "            self.checked[combo] = 1\n",
    "            \n",
    "            if self.clf_type == 'Regression':\n",
    "                self.result[combo] = row[1]['Val r2']\n",
    "            elif self.clf_type == 'Classification':\n",
    "                self.result[combo] = row[1]['Val accu']\n",
    "        \n",
    "            # update best score stats\n",
    "            if self.result[combo] > self.best_score: \n",
    "                self.best_score = self.result[combo]\n",
    "                self.best_clf = None\n",
    "                print(f\"As new Best Combo {combo} is read in, best_clf is set to None\")\n",
    "                self.best_combo = combo\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self.parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self.parameter_value_map_index[key] = tmp\n",
    "    \n",
    "\n",
    "\n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "    \n",
    "    def _set_object_saving_address(self, address):\n",
    "        \"\"\" Read in where to save the JiaoCheng object \"\"\"\n",
    "\n",
    "        self.object_saving_address = address\n",
    "        print('Successfully set object output address')\n",
    "\n",
    "\n",
    "\n",
    "    def export_jiaocheng(self, address):\n",
    "        \"\"\" Export jiaocheng object \"\"\"\n",
    "\n",
    "        self._set_object_saving_address(address)\n",
    "\n",
    "        # copy object and set big objects to None\n",
    "        object_save = copy.deepcopy(self)\n",
    "        \n",
    "        object_save.train_x = None\n",
    "        object_save.train_y = None\n",
    "        object_save.val_x = None\n",
    "        object_save.val_y = None\n",
    "        object_save.test_x = None\n",
    "        object_save.test_y = None\n",
    "        object_save._up_to = 0\n",
    "\n",
    "        # Export\n",
    "        object_saving_address_strip = self.object_saving_address.split('.pickle')[0]\n",
    "        with open(f'{object_saving_address_strip}.pickle', 'wb') as f:\n",
    "            pickle.dump(object_save, f)\n",
    "\n",
    "        print(f'Successfully exported JiaoCheng object as {self.object_saving_address}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_choices = {\n",
    "    'gamma': (0, 0.0001, 1000, 1, 100),\n",
    "    'subsample': (0.25, 0.5, 0.75),\n",
    "    'colsample_bytree': (0.25, 0.5, 0.75),\n",
    "    'max_depth': (5, 10, 25, 50, 100),\n",
    "    'eta': (0.15, 0.3, 0.45, 0.6, 0.75, 0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': (0, 0.0001, 1000, 1, 100),\n",
       " 'subsample': (0.25, 0.5, 0.75),\n",
       " 'colsample_bytree': (0.25, 0.5, 0.75),\n",
       " 'max_depth': (5, 10, 25, 50, 100),\n",
       " 'eta': (0.15, 0.3, 0.45, 0.6, 0.75, 0.9)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in parameter_choices:\n",
    "    tmp = copy.deepcopy(list(parameter_choices[key]))\n",
    "    tmp.sort()\n",
    "    parameter_choices[key] = tuple(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': (0, 0.0001, 1, 100, 1000),\n",
       " 'subsample': (0.25, 0.5, 0.75),\n",
       " 'colsample_bytree': (0.25, 0.5, 0.75),\n",
       " 'max_depth': (5, 10, 25, 50, 100),\n",
       " 'eta': (0.15, 0.3, 0.45, 0.6, 0.75, 0.9)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
