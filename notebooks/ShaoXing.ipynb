{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShaoXing:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('ShaoXing Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \n",
    "        self._seed = 18980305\n",
    "        self.train_analyse_df = None\n",
    "        self.val_analyse_df = None\n",
    "        self.test_analyse_df = None\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_features_label(self, features, label):\n",
    "\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_full_train_test_data(self, full_data, train_data, val_data, test_data):\n",
    "        \"\"\" Read in Full, Train, Validate, Test data along with features list and labels, auto transforms to x, y \"\"\"\n",
    "\n",
    "        if self.features == None or self.label == None:\n",
    "            print(\"Missing features list and label. Please run .read_in_features_label before running this function\")\n",
    "            return\n",
    "\n",
    "        for col in self.features:\n",
    "            assert col in full_data.columns\n",
    "            assert col in train_data.columns\n",
    "            assert col in val_data.columns\n",
    "            assert col in test_data.columns\n",
    "\n",
    "        \n",
    "\n",
    "        self.full_data = full_data\n",
    "        print('Full Data read in successfully')\n",
    "        self.train_data = train_data\n",
    "        print('Train Data read in successfully')\n",
    "        self.val_data = val_data\n",
    "        print('Validation Data read in successfully')\n",
    "        self.test_data = test_data\n",
    "        print('Test Data read in successfully')\n",
    "\n",
    "\n",
    "        self.train_x, self.train_y = self._separate_feature_label(train_data)\n",
    "        self.val_x, self.val_y = self._separate_feature_label(val_data)\n",
    "        self.test_x, self.test_y = self._separate_feature_label(test_data)\n",
    "    \n",
    "\n",
    "\n",
    "    def _separate_feature_label(self, data):\n",
    "        return data[self.features], data[self.label]\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_future_data(self, future_data):\n",
    "        \"\"\" Read in Train Test Split data \"\"\"\n",
    "\n",
    "        assert len(future_data.columns) in (len(self.features), len(self.features)+ 1)\n",
    "\n",
    "        for col in self.features:\n",
    "            assert col in future_data.columns\n",
    "        \n",
    "        self.future_pred = None # reset future predictions given new data\n",
    "        self.future_data_and_pred = None\n",
    "\n",
    "        self.future_data = future_data\n",
    "        print('Future Data read in successfully')\n",
    "\n",
    "\n",
    "    \n",
    "    def read_in_untrained_model(self, model_class, best_params, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model_fitted = 0\n",
    "        self.model_class = model_class\n",
    "        self.clf_type = type \n",
    "        self.parameters = best_params\n",
    "\n",
    "        print(f'Successfully read in untrained model {self.model_class} with hyperparameters {self.parameters}, which is a {self.clf_type} model')\n",
    "    \n",
    "\n",
    "    \n",
    "    def read_in_fitted_model(self, fitted_model, type):\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "        \n",
    "        self.model = fitted_model\n",
    "        self.clf_type = type\n",
    "        \n",
    "        self.model_fitted = 1\n",
    "\n",
    "        print(f'Successfully read in fitted model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "    \n",
    "    def fit_model(self):\n",
    "\n",
    "        if self.model_class == None or self.parameters == None:\n",
    "            print('Missing model_class or parameters, please run .read_in_untrained_model()')\n",
    "\n",
    "        start = time.time()\n",
    "        self.model = self.model_class(**self.parameters)\n",
    "        self.model.fit(self.train_x, self.train_y)\n",
    "        end = time.time()\n",
    "\n",
    "        self.model_fit_time = end - start\n",
    "\n",
    "        self.model_fitted = 1\n",
    "        print(f'Model fitted, taking {self.model_fit_time} seconds')\n",
    "\n",
    "\n",
    "\n",
    "    def export_model(self, model_export_address):\n",
    "\n",
    "        if self.model_fitted == 0:\n",
    "            print('Please fit model using .fit_model() before exporting')\n",
    "            return\n",
    "        \n",
    "        model_export_address_strip = model_export_address.split('.pickle')[0]\n",
    "\n",
    "        with open(f'{model_export_address_strip}.pickle', 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "    \n",
    "\n",
    "\n",
    "    def predict_using_future_data(self, return_pred = False):\n",
    "\n",
    "        if self.model_fitted == 0:\n",
    "            print('Model not fitted, please use .read_in_fitted_model() to read in a fitted model or .fit_model() to fit model')\n",
    "            return\n",
    "        \n",
    "        self.future_pred = self.model.predict(self.future_data)\n",
    "\n",
    "        if return_pred:\n",
    "            return self.future_pred\n",
    "        \n",
    "\n",
    "    \n",
    "    def export_future_data_and_predictions(self, future_data_and_pred_saving_address):\n",
    "\n",
    "        assert self.future_pred\n",
    "\n",
    "        self.future_data_and_pred = copy.deepcopy(self.future_data)\n",
    "        self.future_data_and_pred['Pred'] = self.future_pred\n",
    "\n",
    "        future_data_and_pred_saving_address_strip = future_data_and_pred_saving_address.split('.csv')[0]\n",
    "            \n",
    "        self.tuning_result.to_csv(f'{future_data_and_pred_saving_address_strip}.csv', index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    def view_future_data_and_predictions(self, return_df = False):\n",
    "\n",
    "        if self.future_data_and_pred == None:\n",
    "            self.future_data_and_pred = copy.deepcopy(self.future_data)\n",
    "            self.future_data_and_pred['Pred'] = self.future_pred\n",
    "        \n",
    "        if return_df:\n",
    "            return self.future_data_and_pred\n",
    "        else:\n",
    "            display(self.future_data_and_pred)\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_analysis(self):\n",
    "        self.train_pred = self.model.predict(self.train_x)\n",
    "        self.val_pred = self.model.predict(self.val_x)\n",
    "        self.test_pred = self.model.predict(self.test_x)\n",
    "\n",
    "        # Normal stats\n",
    "        if self.clf_type == 'Regression':\n",
    "            train_score = r2_score(self.train_y, self.train_pred)\n",
    "            val_score = r2_score(self.val_y, self.val_pred)\n",
    "            test_score = r2_score(self.test_y, self.test_pred)\n",
    "\n",
    "            train_rmse = np.sqrt(mean_squared_error(self.train_y, self.train_pred))\n",
    "            val_rmse = np.sqrt(mean_squared_error(self.val_y, self.val_pred))\n",
    "            test_rmse = np.sqrt(mean_squared_error(self.test_y, self.test_pred))\n",
    "\n",
    "            train_mape = mean_absolute_percentage_error(self.train_y, self.train_pred)\n",
    "            val_mape = mean_absolute_percentage_error(self.val_y, self.val_pred)\n",
    "            test_mape = mean_absolute_percentage_error(self.test_y, self.test_pred)\n",
    "\n",
    "\n",
    "            # Quartile Stats:\n",
    "            train_quantile4_n, train_quantile4_r2, train_quantile4_RMSE, \\\n",
    "                train_quantile4_MAPE, val_quantile4_n, val_quantile4_r2, \\\n",
    "                    val_quantile4_RMSE, val_quantile4_MAPE, test_quantile4_n, \\\n",
    "                        test_quantile4_r2, test_quantile4_RMSE, test_quantile4_MAPE = \\\n",
    "                            self._quantily_stats(4)\n",
    "            \n",
    "            train_quantile10_n, train_quantile10_r2, train_quantile10_RMSE, \\\n",
    "                train_quantile10_MAPE, val_quantile10_n, val_quantile10_r2, \\\n",
    "                    val_quantile10_RMSE, val_quantile10_MAPE, test_quantile10_n, \\\n",
    "                        test_quantile10_r2, test_quantile10_RMSE, test_quantile10_MAPE = \\\n",
    "                            self._quantily_stats(10)\n",
    "            \n",
    "            # CV\n",
    "            cv_r2_score, cv_rmse_score, cv_mape_score = self._get_CV_stats()\n",
    "\n",
    "            # Diagram\n",
    "    \n",
    "        elif self.clf_type == 'Classification':\n",
    "            train_score = self.model.score(self.train_y, self.train_pred)\n",
    "            val_score = self.model.score(self.val_y, self.val_pred)\n",
    "            test_score = self.model.score(self.test_y, self.test_pred)\n",
    "\n",
    "            train_bal_accu = balanced_accuracy_score(self.train_y, self.train_pred)\n",
    "            val_bal_accu = balanced_accuracy_score(self.val_y, self.val_pred)\n",
    "            test_bal_accu = balanced_accuracy_score(self.test_y, self.test_pred)\n",
    "\n",
    "            train_f1 = f1_score(self.train_y, self.train_pred, average='weighted')\n",
    "            val_f1 = f1_score(self.val_y, self.val_pred, average='weighted')\n",
    "            test_f1 = f1_score(self.test_y, self.test_pred, average='weighted')\n",
    "\n",
    "            train_precision = precision_score(self.train_y, self.train_pred, average='weighted')\n",
    "            val_precision = precision_score(self.val_y, self.val_pred, average='weighted')\n",
    "            test_precision = precision_score(self.test_y, self.test_pred, average='weighted')\n",
    "\n",
    "            train_recall = recall_score(self.train_y, self.train_pred, average='weighted')\n",
    "            val_recall = recall_score(self.val_y, self.val_pred, average='weighted')\n",
    "            test_recall = recall_score(self.test_y, self.test_pred, average='weighted')\n",
    "\n",
    "            #TODO: MORE STATS    \n",
    "\n",
    "            # CV\n",
    "            cv_accuracy_score, cv_bal_accuracy_score, cv_f1_score, cv_precision_score, cv_recall_score = self._get_CV_stats()\n",
    "\n",
    "            # Diagrams\n",
    "\n",
    "\n",
    "\n",
    "    def _quantily_stats(self, n_quantiles):\n",
    "    \n",
    "        if self.train_analyse_df is None:\n",
    "            self.train_analyse_df = pd.DataFrame({'obs': self.train_y, 'pred': self.train_pred})\n",
    "        \n",
    "        if self.val_analyse_df is None:    \n",
    "            self.val_analyse_df = pd.DataFrame({'obs': self.val_y, 'pred': self.val_pred})\n",
    "        \n",
    "        if self.test_analyse_df is None:\n",
    "            self.test_analyse_df = pd.DataFrame({'obs': self.test_y, 'pred': self.test_pred})\n",
    "        \n",
    "        quantiles_p = [i/n_quantiles for i in range(n_quantiles+1)]\n",
    "\n",
    "        train_quantiles = list(self.train_y.quantile(quantiles_p))\n",
    "        val_quantiles = list(self.val_y.quantile(quantiles_p))\n",
    "        test_quantiles = list(self.test_y.quantile(quantiles_p))\n",
    "\n",
    "        train_quantile_n = list()\n",
    "        val_quantile_n = list()\n",
    "        test_quantile_n = list()\n",
    "\n",
    "        train_quantile_r2 = list()\n",
    "        val_quantile_r2 = list()\n",
    "        test_quantile_r2 = list()\n",
    "\n",
    "        train_quantile_RMSE = list()\n",
    "        val_quantile_RMSE = list()\n",
    "        test_quantile_RMSE = list()\n",
    "\n",
    "        train_quantile_MAPE = list()\n",
    "        val_quantile_MAPE = list()\n",
    "        test_quantile_MAPE = list()\n",
    "\n",
    "        for analyse_df, quantiles, stats in ((self.train_analyse_df, train_quantiles, (train_quantile_n, train_quantile_r2, train_quantile_RMSE, train_quantile_MAPE)), \\\n",
    "            (self.val_analyse_df, val_quantiles, (val_quantile_n, val_quantile_r2, val_quantile_RMSE, val_quantile_MAPE)), \\\n",
    "            (self.test_analyse_df, test_quantiles, (test_quantile_n, test_quantile_r2, test_quantile_RMSE, test_quantile_MAPE))):\n",
    "\n",
    "            for i in range(n_quantiles):\n",
    "                if i == 0:\n",
    "                    q_df = analyse_df[(analyse_df['obs'] >= quantiles[i])\n",
    "                        & (analyse_df['obs'] <= quantiles[i+1])]\n",
    "                else:\n",
    "                    q_df = analyse_df[(analyse_df['obs'] > quantiles[i])\n",
    "                        & (analyse_df['obs'] <= quantiles[i+1])]\n",
    "                \n",
    "                stats[0].append(len(q_df))\n",
    "\n",
    "                try:\n",
    "                    q_r2 = r2_score(q_df['obs'], q_df['pred']) # when all values of obs is the same, r2 will always be 0\n",
    "                except:\n",
    "                    q_r2 = np.nan\n",
    "\n",
    "                try:\n",
    "                    q_rmse = np.sqrt(mean_squared_error(q_df['obs'], q_df['pred']))\n",
    "                except:\n",
    "                    q_rmse = np.nan\n",
    "\n",
    "                try:\n",
    "                    q_mape = mean_absolute_percentage_error(q_df['obs'], q_df['pred'])\n",
    "                except:\n",
    "                    q_mape = np.nan\n",
    "                \n",
    "                stats[1].append(q_r2)\n",
    "                stats[2].append(q_rmse)\n",
    "                stats[3].append(q_mape)\n",
    "\n",
    "        return train_quantile_n, train_quantile_r2, train_quantile_RMSE, train_quantile_MAPE, val_quantile_n, val_quantile_r2, val_quantile_RMSE, val_quantile_MAPE, test_quantile_n, test_quantile_r2, test_quantile_RMSE, test_quantile_MAPE\n",
    "    \n",
    "\n",
    "\n",
    "    def _get_CV_stats(self):\n",
    "\n",
    "        shuffled_full_data = self.full_data.sample(frac = 1, random_state = 18980305) # use sample to shuffle\n",
    "        shuffled_full_data.index = range(len(shuffled_full_data))\n",
    "\n",
    "        n = len(shuffled_full_data)\n",
    "        shuffled_index = [0, int(n/5), int(2*n/5), int(3*n/5), int(4*n/5), n]\n",
    "        \n",
    "        if self.clf_type == 'Regression':\n",
    "            r2_scores = list()\n",
    "            rmse_scores = list()\n",
    "            mape_scores = list()\n",
    "\n",
    "        elif self.clf_type == 'Classification': #TODO\n",
    "            accuracy_scores = list()\n",
    "            bal_accuracy_scores = list()\n",
    "            f1_scores = list()\n",
    "            precision_scores = list()\n",
    "            recall_scores = list()\n",
    "\n",
    "\n",
    "        for i in range(5):\n",
    "            cv_train1 = shuffled_full_data[0:shuffled_index[i]] \n",
    "            cv_train2 = shuffled_full_data[shuffled_index[i+1]:n]\n",
    "            cv_train = cv_train1.append(cv_train2)\n",
    "            cv_test = shuffled_full_data[shuffled_index[i]:shuffled_index[i+1]]\n",
    "\n",
    "            cv_train_x = cv_train[self.features]\n",
    "            cv_train_y = cv_train[self.label]\n",
    "            cv_test_x = cv_test[self.features]\n",
    "            cv_test_y = cv_test[self.label]\n",
    "\n",
    "            cv_model = copy.deepcopy(self.model)\n",
    "            cv_model.fit(cv_train_x, cv_train_y)\n",
    "\n",
    "            cv_test_pred = cv_model.predict(cv_test_x)\n",
    "            \n",
    "            if self.clf_type == 'Regression':\n",
    "                r2_scores.append(r2_score(cv_test_y, cv_test_pred))\n",
    "                rmse_scores.append(np.sqrt(mean_squared_error(cv_test_y, cv_test_pred)))\n",
    "                mape_scores.append(mean_absolute_percentage_error(cv_test_y, cv_test_pred))\n",
    "\n",
    "            elif self.clf_type == 'Classification': #TODO\n",
    "                accuracy_scores.append(cv_model.score(cv_test_y, cv_test_pred))\n",
    "                bal_accuracy_scores.append(balanced_accuracy_score(cv_test_y, cv_test_pred))\n",
    "                f1_scores.append(f1_score(cv_test_y, cv_test_pred))\n",
    "                precision_scores.append(precision_score(cv_test_y, cv_test_pred))\n",
    "                recall_scores.append(recall_score(cv_test_y, cv_test_pred))\n",
    "            \n",
    "        if self.clf_type == 'Regression':\n",
    "            cv_r2_score = np.mean(r2_scores)\n",
    "            cv_rmse_score = np.mean(rmse_scores)\n",
    "            cv_mape_score = np.mean(mape_scores)\n",
    "\n",
    "            return cv_r2_score, cv_rmse_score, cv_mape_score\n",
    "            \n",
    "        elif self.clf_type == 'Classification': #TODO\n",
    "            cv_accuracy_score = np.mean(accuracy_scores)\n",
    "            cv_bal_accuracy_score = np.mean(bal_accuracy_scores)\n",
    "            cv_f1_score = np.mean(f1_scores)\n",
    "            cv_precision_score = np.mean(precision_scores)\n",
    "            cv_recall_score = np.mean(recall_scores)\n",
    "\n",
    "            return cv_accuracy_score, cv_bal_accuracy_score, cv_f1_score, cv_precision_score, cv_recall_score\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('../data/curated/modelling/N_Full_3.csv')\n",
    "train_data = pd.read_csv('../data/curated/modelling/N_Train_3.csv')\n",
    "val_data = pd.read_csv('../data/curated/modelling/N_Validate_3.csv')\n",
    "test_data = pd.read_csv('../data/curated/modelling/N_Test_3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShaoXing Initialised\n"
     ]
    }
   ],
   "source": [
    "shaoxing = ShaoXing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZhongShan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/AFL_pipeline_N.pickle', 'rb') as f:\n",
    "    sanmin = pickle.load(f)\n",
    "    \n",
    "model3_COLS = sanmin.final_features['3']\n",
    "# model2_COLS = sanmin.final_features['2']\n",
    "# model1_COLS = sanmin.final_features['1']\n",
    "\n",
    "model3_COLS = [x for x in model3_COLS if x not in ['3', '2', '1']]\n",
    "# model2_COLS = [x for x in model2_COLS if x not in ['3', '2', '1']]\n",
    "# model1_COLS = [x for x in model1_COLS if x not in ['3', '2', '1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaoxing.read_in_features_label(model3_COLS, '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data read in successfully\n",
      "Train Data read in successfully\n",
      "Validation Data read in successfully\n",
      "Test Data read in successfully\n"
     ]
    }
   ],
   "source": [
    "shaoxing.read_in_full_train_test_data(full_data, train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor as GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GBR\n",
    "params = {'learning_rate':0.01, \n",
    "    'n_estimators':200, \n",
    "    'subsample' : 0.5, \n",
    "    'max_features':0.5, \n",
    "    'ccp_alpha':0, \n",
    "    'max_depth':5, \n",
    "    'random_state' : 19260817}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/final_models/model3.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read in fitted model GradientBoostingRegressor(ccp_alpha=0, learning_rate=0.01, max_depth=5,\n",
      "                          max_features=0.5, n_estimators=200,\n",
      "                          random_state=19260817, subsample=0.5), which is a Regression model\n"
     ]
    }
   ],
   "source": [
    "shaoxing.read_in_fitted_model(model, 'Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shaoxing.read_in_untrained_model(gbr, params, 'Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shaoxing.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47328\n",
      "11831\n",
      "47327\n",
      "11832\n",
      "47327\n",
      "11832\n",
      "47327\n",
      "11832\n",
      "47327\n",
      "11832\n"
     ]
    }
   ],
   "source": [
    "shaoxing.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
