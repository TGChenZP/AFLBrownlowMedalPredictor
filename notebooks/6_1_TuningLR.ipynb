{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = 'RS'\n",
    "LABEL = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class JiXi:\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('JiXi Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self._up_to = 0\n",
    "        self._seed = 19421221\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.combos = None\n",
    "        self.n_items = None\n",
    "        self.outmost_layer = None\n",
    "        self._core = None\n",
    "        self._relative_combos = None\n",
    "        self._both_combos = None\n",
    "        self._dealt_with = None\n",
    "        self._pos_neg_combos = None\n",
    "        self._abs_max = None\n",
    "        self._new_combos = None\n",
    "        self._parameter_value_map_index = None\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "        \n",
    "\n",
    "    def read_in_data(self, train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.train_x = train_x\n",
    "        print(\"Read in Train X data\")\n",
    "\n",
    "        self.train_y = train_y\n",
    "        print(\"Read in Train x data\")\n",
    "\n",
    "        self.val_x = val_x\n",
    "        print(\"Read in Val X data\")\n",
    "\n",
    "        self.val_y = val_y\n",
    "        print(\"Read in Val y data\")\n",
    "\n",
    "        self.test_x = test_x\n",
    "        print(\"Read in Test X data\")\n",
    "\n",
    "        self.test_y = test_y\n",
    "        print(\"Read in Test y data\")\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self._sort_hyperparameter_choices()\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_combinations()\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_combinations(self):\n",
    "        \"\"\" Helper to calculate all combinations \"\"\"\n",
    "\n",
    "        ##ALGORITHM\n",
    "\n",
    "        # recursively append values to get every combination in ordinal/numerical form\n",
    "        self.combos = [[]]\n",
    "        for i in range(len(self.n_items)):\n",
    "\n",
    "            tmp = copy.deepcopy(self.combos)\n",
    "            self.combos = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in range(self.n_items[i]):\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self.combos.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "    \n",
    "    def change_tuning_style(self, type, seed = None, outer_most_layer = 2, randomise = True): \n",
    "        # Function which determines how to order the combinations for tuning\n",
    "\n",
    "        if not self.combos:\n",
    "            print(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            return\n",
    "\n",
    "        self.combos.sort() # to ensure functionality of seed, always sort first\n",
    "\n",
    "        if type == 'a': # Sorted order (nested loops)\n",
    "            # sorting operation conducted previously\n",
    "            print('Changed tuning order to sorted')\n",
    "        \n",
    "        elif type == 'b': # Random order\n",
    "            \n",
    "            if seed:\n",
    "                random.seed(seed)\n",
    "            else:\n",
    "                random.seed(self._seed)\n",
    "            \n",
    "            random.shuffle(self.combos)\n",
    "            print('Changed tuning_order to randomised')\n",
    "        \n",
    "        elif type == 'c': # Layer by Layer \n",
    "            self._change_tuning_style_c(outer_most_layer, randomise, seed)\n",
    "            if randomise:\n",
    "                print(f'Changed tuning order to \"Layer by Layer\": {self.outmost_layer} Layers, randomised')\n",
    "            else:\n",
    "                print(f'Changed tuning order to \"Layer by Layer\": {self.outmost_layer} Layers, not randomised')\n",
    "\n",
    "        elif type == 'd': # Diagonal + Horizontal first, before conducting layer by layer\n",
    "            self._change_tuning_style_d()\n",
    "            print(f'Changed tuning order to Diag-Hor -> \"Layer by Layer\": {self.outmost_layer} Layers, randomised')\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_relative_combos(self):\n",
    "        \"\"\" Helper to calculate relative coordinates of combinations\"\"\" \n",
    "        self._relative_combos = [[combo[j] - self._core[j] for j in range(len(self.n_items))] for combo in self.combos]\n",
    "\n",
    "\n",
    "\n",
    "    ### TYPE C\n",
    "    def _get_both_combos(self):\n",
    "        \"\"\" Helper to put (combos, relative combos) together into a tuple \"\"\"\n",
    "        self._get_relative_combos()\n",
    "        self._both_combos = [[self.combos[i], self._relative_combos[i]] for i in range(len(self.combos))]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_layer_by_layer(self):\n",
    "        \"\"\" Helper to get Layer by Layer order \"\"\"\n",
    "\n",
    "        retain = copy.deepcopy(self._both_combos)\n",
    "        self._dealt_with = list()\n",
    "\n",
    "        # starting with the outmost layer, ending with -1 because of the >\n",
    "        for i in range(self.outmost_layer, -2, -1):\n",
    "            tmp_retain = list()\n",
    "            tmp_dealt_with = list()\n",
    "            \n",
    "            for item in retain:\n",
    "\n",
    "                trigger = 1\n",
    "                for j in item[1]:\n",
    "                    if abs(j) > i:\n",
    "                        tmp_dealt_with.append(item[0])\n",
    "                        trigger = 0\n",
    "                        break\n",
    "                \n",
    "                if trigger:\n",
    "                    tmp_retain.append(item)\n",
    "\n",
    "            retain = tmp_retain\n",
    "            self._dealt_with.append(tmp_dealt_with)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_c_combos(self):\n",
    "        \"\"\" Helper to get the combinations into Layer by Layer order \"\"\"\n",
    "\n",
    "        self.combos = list()\n",
    "        # working with dealt_with backwards because we want the innermost layers first\n",
    "        for i in range(len(self._dealt_with)-1, -1, -1):\n",
    "            self.combos.extend(self._dealt_with[i])\n",
    "            \n",
    "\n",
    "\n",
    "    def _change_tuning_style_c(self, outmost_layer, randomise, seed):\n",
    "        \"\"\" Helper to run all type-c helpers to get combinations into Layer by Layer order \"\"\"\n",
    "\n",
    "        if randomise:\n",
    "            if seed:\n",
    "                random.seed(seed)\n",
    "            else:\n",
    "                random.seed(self._seed)\n",
    "        \n",
    "        random.shuffle(self.combos)\n",
    "\n",
    "        self.outmost_layer = outmost_layer\n",
    "        self._get_core()\n",
    "        self._get_both_combos()\n",
    "        self._get_layer_by_layer()\n",
    "        self._get_c_combos()\n",
    "\n",
    "\n",
    "\n",
    "    ### TYPE D    \n",
    "    def _change_tuning_style_d(self):\n",
    "        \"\"\" Helper to all type-d helpers to get combinations into Layer by Layer order \"\"\"\n",
    "\n",
    "        self._change_tuning_style_c(outmost_layer= max(self.n_items), randomise = True, seed = self._seed)\n",
    "\n",
    "        self._get_hor_combos()\n",
    "        self._get_diag_combos()\n",
    "\n",
    "        self._get_d_combos()\n",
    "\n",
    "\n",
    "\n",
    "    def _get_hor_combos(self):\n",
    "        \"\"\" Helper to get all combinations that lie on horizontal line from core \"\"\"\n",
    "        self._hor_combos = list()\n",
    "        for i in range(len(self.n_items)):\n",
    "            for j in range(self.n_items[i]):\n",
    "                tmp = copy.deepcopy(self._core)\n",
    "                tmp[i] = j\n",
    "                self._hor_combos.append(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_pos_neg_combos(self):\n",
    "        \"\"\" Helper to get all combinations of -1 and 1 \"\"\"\n",
    "\n",
    "        ##ALGORITHM\n",
    "        self._pos_neg_combos = [[]]\n",
    "        for i in range(len(self.n_items)):\n",
    "\n",
    "            tmp = copy.deepcopy(self._pos_neg_combos)\n",
    "            self._pos_neg_combos = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in (-1, 1):\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self._pos_neg_combos.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_abs_max(self):\n",
    "        \"\"\" Helper to get maximum absolute value of the relative combos \"\"\"\n",
    "\n",
    "        max_pos = max([self.n_items[i] - self._core[i] for i in range(len(self.n_items))])\n",
    "        min_neg = min([0-self._core[i] for i in range(len(self.n_items))])\n",
    "\n",
    "        self._abs_max = max((max_pos, abs(min_neg)))\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diag_combos(self):\n",
    "        \"\"\" Helper to get all combinations that lie on diagonal line from core \"\"\"\n",
    "\n",
    "        # Implementation idea: first get all the diagonal combos (even those that go outside the field-space) \n",
    "        # by using all combinations of (-1, 1) multipled by each value from 1 to _abs_max, before eliminating combos that go\n",
    "        # outside the field-space\n",
    "        self._get_pos_neg_combos()\n",
    "        self._get_abs_max()\n",
    "\n",
    "        diag_rel_combos = list()\n",
    "        for i in range(self._abs_max):\n",
    "            diag_rel_combos.extend([[(i+1)*pos_neg_combo[j] for j in range(len(self.n_items))] for pos_neg_combo in self._pos_neg_combos])\n",
    "        \n",
    "        tmp_diag_combos = [[combo[j] + self._core[j] for j in range(len(self.n_items))] for combo in diag_rel_combos]\n",
    "\n",
    "        self._diag_combos = list()\n",
    "        \n",
    "        for combo in tmp_diag_combos:\n",
    "            trigger = 1\n",
    "            for i in range(len(combo)):\n",
    "                if combo[i] < 0 or combo[i] >= self.n_items[i]: # if outside field space then eliminate\n",
    "                    trigger = 0\n",
    "                    break\n",
    "            \n",
    "            if trigger:\n",
    "                self._diag_combos.append(combo)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_d_combos(self):\n",
    "        \"\"\" Helper to run all type-c helpers to get combinations into Diag-Hor -> Layer by Layer order \"\"\"\n",
    "\n",
    "        self._new_combos = list()\n",
    "\n",
    "        self._new_combos.append(self._core)\n",
    "\n",
    "        # put in diagonal first to get more variety\n",
    "        for combo in self._diag_combos:\n",
    "            if combo not in self._new_combos:\n",
    "                self._new_combos.append(combo)\n",
    "\n",
    "        for combo in self._hor_combos:\n",
    "            if combo not in self._new_combos:\n",
    "                self._new_combos.append(combo)\n",
    "\n",
    "        # put in rest of the combos - already sorted in layer by layer order\n",
    "        for combo in self.combos:\n",
    "            if combo not in self._new_combos:\n",
    "                self._new_combos.append(combo)\n",
    "        \n",
    "        self.combos = self._new_combos\n",
    "\n",
    "\n",
    "        \n",
    "    def tune(self): #TODO\n",
    "        \"\"\" Begin tuning \"\"\"\n",
    "\n",
    "        if self.train_x is None or self.train_y is None or self.val_x is None or self.val_y is None or self.test_x is None or self.test_y is None:\n",
    "            print(\" Missing one of the datasets, please run .read_in_data() \")\n",
    "            return\n",
    "\n",
    "        if self.model is None:\n",
    "            print(\" Missing model, please run .read_in_model() \")\n",
    "            return\n",
    "        \n",
    "        if self.combos is None:\n",
    "            print(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            return\n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            print(\"Missing tuning result csv saving address, please run ._save_tuning_result() first\")\n",
    "\n",
    "\n",
    "        self._up_to = 0     # reset\n",
    "\n",
    "        for combo in self.combos:\n",
    "            \n",
    "            self._up_to += 1\n",
    "\n",
    "            if not self.checked[tuple(combo)]:\n",
    "\n",
    "                self._train_and_test_combo(combo)\n",
    "            \n",
    "            else:\n",
    "                print(f'Already Trained and Tested combination {self._up_to}')\n",
    "      \n",
    "\n",
    "\n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "\n",
    "        # initialise object\n",
    "        clf = self.model(**params)\n",
    "\n",
    "        # get time and fit\n",
    "        start = time.time()\n",
    "        clf.fit(self.train_x, self.train_y)\n",
    "        end = time.time()\n",
    "\n",
    "        # get predicted labels/values for three datasets\n",
    "        train_pred = clf.predict(self.train_x)\n",
    "        val_pred = clf.predict(self.val_x)\n",
    "        test_pred = clf.predict(self.test_x)\n",
    "\n",
    "        # get scores and time used\n",
    "        time_used = end-start\n",
    "\n",
    "        # build output dictionary and save result\n",
    "        df_building_dict = params\n",
    "\n",
    "        if self.clf_type == 'Regression':\n",
    "            train_score = r2_score(self.train_y, train_pred)\n",
    "            val_score = r2_score(self.val_y, val_pred)\n",
    "            test_score = r2_score(self.test_y, test_pred)\n",
    "\n",
    "            train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "            val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "            test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "\n",
    "            train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "            val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "            test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "\n",
    "            df_building_dict['Train r2'] = [np.round(train_score, 4)]\n",
    "            df_building_dict['Val r2'] = [np.round(val_score, 4)]\n",
    "            df_building_dict['Test r2'] = [np.round(test_score, 4)]\n",
    "            df_building_dict['Train RMSE'] = [np.round(train_rmse, 4)]\n",
    "            df_building_dict['Val RMSE'] = [np.round(val_rmse, 4)]\n",
    "            df_building_dict['Test RMSE'] = [np.round(test_rmse, 4)]\n",
    "            df_building_dict['Train MAPE'] = [np.round(train_mape, 4)]\n",
    "            df_building_dict['Val MAPE'] = [np.round(val_mape, 4)]\n",
    "            df_building_dict['Test MAPE'] = [np.round(test_mape, 4)]\n",
    "            df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "        \n",
    "        elif self.clf_type == 'Classification':\n",
    "            train_score = accuracy_score(self.train_y, train_pred)\n",
    "            val_score = clf.score(self.val_y, val_pred)\n",
    "            test_score = clf.score(self.test_y, test_pred)\n",
    "\n",
    "            train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "            val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "            test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "\n",
    "            train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "            val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "            test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "\n",
    "            train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "            val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "            test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "        \n",
    "            train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "            val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "            test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "\n",
    "            df_building_dict['Train accu'] = [np.round(train_score, 4)]\n",
    "            df_building_dict['Val accu'] = [np.round(val_score, 4)]\n",
    "            df_building_dict['Test accu'] = [np.round(test_score, 4)]\n",
    "            df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 4)]\n",
    "            df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 4)]\n",
    "            df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 4)]\n",
    "            df_building_dict['Train f1'] = [np.round(train_f1, 4)]\n",
    "            df_building_dict['Val f1'] = [np.round(val_f1, 4)]\n",
    "            df_building_dict['Test f1'] = [np.round(test_f1, 4)]\n",
    "            df_building_dict['Train precision'] = [np.round(train_precision, 4)]\n",
    "            df_building_dict['Val precision'] = [np.round(val_precision, 4)]\n",
    "            df_building_dict['Test precision'] = [np.round(test_precision, 4)]\n",
    "            df_building_dict['Train recall'] = [np.round(train_recall, 4)]\n",
    "            df_building_dict['Val recall'] = [np.round(val_recall, 4)]\n",
    "            df_building_dict['Test recall'] = [np.round(test_recall, 4)]\n",
    "            df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "        tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "        self.tuning_result = self.tuning_result.append(tmp)\n",
    "        self._save_tuning_result()\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_clf = clf\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "\n",
    "        print(f'''Trained and Tested combination {self._up_to}, taking {np.round(time_used, 2)} seconds\n",
    "        Current best combo: {self.best_combo} with val score {self.best_score}''')\n",
    "\n",
    "\n",
    "\n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        self.tuning_result.to_csv(f'{self.tuning_result_saving_address}.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print(f'(Current) Best combo: {self.best_combo} with val score {self.best_score}')\n",
    "\n",
    "    \n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            print(\"Missing parameter_choices to build parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            print('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of JiXi\n",
    "        for row in self.tuning_result.iterrows():\n",
    "    \n",
    "            combo = tuple([self._parameter_value_map_index[hyperparam][row[1][hyperparam]] for hyperparam in self.hyperparameters])\n",
    "            \n",
    "            self.checked[combo] = 1\n",
    "            \n",
    "            if self.clf_type == 'Regression':\n",
    "                self.result[combo] = row[1]['Val r2']\n",
    "            elif self.clf_type == 'Classification':\n",
    "                self.result[combo] = row[1]['Val accu']\n",
    "        \n",
    "            # update best score stats\n",
    "            if self.result[combo] > self.best_score: \n",
    "                self.best_score = self.result[combo]\n",
    "                self.best_clf = None\n",
    "                print(f\"As new Best Combo {combo} is read in, best_clf is set to None\")\n",
    "                self.best_combo = combo\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self._parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self._parameter_value_map_index[key] = tmp\n",
    "    \n",
    "\n",
    "\n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "    \n",
    "    def _set_object_saving_address(self, address):\n",
    "        \"\"\" Read in where to save the JiXi object \"\"\"\n",
    "\n",
    "        self.object_saving_address = address\n",
    "        print('Successfully set object output address')\n",
    "\n",
    "\n",
    "\n",
    "    def export_jixi(self, address):\n",
    "        \"\"\" Export jixi object \"\"\"\n",
    "\n",
    "        self._set_object_saving_address(address)\n",
    "\n",
    "        # copy object and set big objects to None\n",
    "        object_save = copy.deepcopy(self)\n",
    "        \n",
    "        object_save.train_x = None\n",
    "        object_save.train_y = None\n",
    "        object_save.val_x = None\n",
    "        object_save.val_y = None\n",
    "        object_save.test_x = None\n",
    "        object_save.test_y = None\n",
    "        object_save._up_to = 0\n",
    "\n",
    "        # Export\n",
    "        with open(f'{self.object_saving_address}.pickle', 'wb') as f:\n",
    "            pickle.dump(object_save, f)\n",
    "\n",
    "        print(f'Successfully exported JiXi object as {self.object_saving_address}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZhongShan import *\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JiaoCheng:\n",
    "\n",
    "    def __init__(self, sanmin):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self.sanmin = sanmin\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('JiaoCheng Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_feature_combinations(self, score_type, label, penalty_function_type, export_address = None):\n",
    "        \"\"\" Function that gets combinations based on JiaoCheng's algorithm along with its score, based on\n",
    "        inputted score type, label and penalty function type. Has option to export\"\"\"\n",
    "\n",
    "        if score_type not in ('NMI', 'Abs Corr'):\n",
    "            print(\"score_type should be either 'NMI' or 'Abs Corr'\")\n",
    "            return\n",
    "        \n",
    "        if label not in self.sanmin.label_columns:\n",
    "            print(\"label should be in the designated labels column\")\n",
    "            return\n",
    "\n",
    "        if penalty_function_type not in ('None', 'Mean', 'Max'):\n",
    "            print(\"penalty_function_type should be either 'None' or 'Mean' or 'Max'\")\n",
    "            return\n",
    "\n",
    "        # get the correct matrix\n",
    "        if score_type == 'Abs Corr':\n",
    "            score_matrix = self.sanmin.abs_corr_matrix\n",
    "        elif score_type == 'NMI':\n",
    "            score_matrix = self.sanmin.NMI_matrix\n",
    "            \n",
    "        # get the correct penalty function\n",
    "        if penalty_function_type == 'None':\n",
    "            funct = self._return_zero\n",
    "        elif penalty_function_type == 'Mean':\n",
    "            funct = np.mean\n",
    "        elif penalty_function_type == 'Max':\n",
    "            funct = max\n",
    "\n",
    "        # object to output\n",
    "        feature_combos_with_score = list()\n",
    "\n",
    "        # starting with each individual feature\n",
    "        for feature in self.sanmin.final_features[label]:\n",
    "            if feature in self.sanmin.label_columns: # don't add if it is a label\n",
    "                continue\n",
    "\n",
    "            # initial current combo\n",
    "            curr_combo = [feature]\n",
    "\n",
    "            # initial current score\n",
    "            curr_combo_score = score_matrix.loc[feature][label]\n",
    "\n",
    "            # initial combo appended with its score\n",
    "            feature_combos_with_score.append((copy.deepcopy(curr_combo), curr_combo_score))\n",
    "\n",
    "            switch = True\n",
    "\n",
    "            while switch is True:\n",
    "\n",
    "                # temporary scores\n",
    "                curr_added_value = 0\n",
    "                curr_feature_to_add = None\n",
    "\n",
    "                # for all try-able combinations\n",
    "                for candidate_feature in self.sanmin.final_features[label]: \n",
    "                    if candidate_feature in curr_combo or candidate_feature in self.sanmin.label_columns: # don't try those already in, nor those that are labels\n",
    "                        continue\n",
    "                    \n",
    "                    # get candidate's own corr with label\n",
    "                    candidate_feature_score = score_matrix.loc[candidate_feature][label]\n",
    "\n",
    "                    # get list of corr between candidate and features currently in combo\n",
    "                    candidate_feature_relation_scores = list()\n",
    "                    for curr_combo_feature in curr_combo:\n",
    "                        candidate_feature_relation_scores.append(score_matrix.loc[candidate_feature][curr_combo_feature])\n",
    "                    \n",
    "                    # if candidate score - penalty > current best, then accept; else, don't accept\n",
    "                    if candidate_feature_score - funct(candidate_feature_relation_scores) >= curr_added_value:\n",
    "                        curr_added_value = candidate_feature_score - funct(candidate_feature_relation_scores)\n",
    "                        curr_feature_to_add = candidate_feature\n",
    "\n",
    "                # if managed to add something to combo, then continue loop and add to overall list, else break this loop\n",
    "                if curr_feature_to_add is None:\n",
    "                    switch = False\n",
    "\n",
    "                else:\n",
    "                    curr_combo.append(curr_feature_to_add)\n",
    "                    curr_combo_score += curr_added_value\n",
    "                    feature_combos_with_score.append((copy.deepcopy(curr_combo), curr_combo_score))\n",
    "\n",
    "        # Remove duplicates and sort\n",
    "        feature_combos_with_score = self._features_duplicate_removal(feature_combos_with_score)\n",
    "        feature_combos_with_score.sort(key = lambda x: x[1])\n",
    "\n",
    "        # Get pure feature combinations, and scores of feature combinations\n",
    "        feature_combo = [feature_combo[0] for feature_combo in feature_combos_with_score]\n",
    "        feature_combo_scores = [feature_combo[1] for feature_combo in feature_combos_with_score]\n",
    "\n",
    "        print(f\"{len(feature_combos_with_score)} feature combinations, with combo scores ranging from {round(feature_combo_scores[0], 4)} to {round(feature_combo_scores[-1], 4)}\")\n",
    "        \n",
    "\n",
    "        # Export combinations and scores as a json\n",
    "        if export_address:\n",
    "            json_output = {'feature_combos_with_score': feature_combos_with_score, \n",
    "                            'feature_combo': feature_combo, \n",
    "                            'feature_combo_scores': feature_combo_scores}\n",
    "                            \n",
    "            with open(f'{export_address}.json', 'w') as f:\n",
    "                json.dump(json_output, f, indent=2) \n",
    "            print(\"Export Completed\")\n",
    "    \n",
    "        return feature_combos_with_score, feature_combo, feature_combo_scores\n",
    "\n",
    "\n",
    "    def _return_zero(self, dummy):\n",
    "        \"\"\" Helper function that returns 0 for penalty, no matter input \"\"\"\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "    def _features_duplicate_removal(self, feature_combos_with_score):\n",
    "        \"\"\" Helper function that remove duplicate combinations \"\"\"\n",
    "        for i in range(len(feature_combos_with_score)):\n",
    "            feature_combos_with_score[i][0].sort()\n",
    "\n",
    "        feature_combos_with_score.sort(key = lambda x:x[0])\n",
    "\n",
    "        duplicate_i = []\n",
    "\n",
    "        feature_combos_no_duplicates = []\n",
    "\n",
    "        for i in range(len(feature_combos_with_score)-1):\n",
    "            if i in duplicate_i:\n",
    "                continue\n",
    "\n",
    "            if feature_combos_with_score[i][0] == feature_combos_with_score[i+1][0]:\n",
    "                # retain the higher score\n",
    "                if feature_combos_with_score[i][1] >= feature_combos_with_score[i+1][1]:\n",
    "                    duplicate_i.append(i)\n",
    "                else:\n",
    "                    duplicate_i.append(i+1)\n",
    "            \n",
    "            if i not in duplicate_i:\n",
    "                feature_combos_no_duplicates.append(feature_combos_with_score[i])\n",
    "\n",
    "        return feature_combos_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/AFL_pipeline_{DATA_TYPE}.pickle', 'rb') as f:\n",
    "    sanmin = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JiaoCheng Initialised\n"
     ]
    }
   ],
   "source": [
    "jiaocheng = JiaoCheng(sanmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409 feature combinations, with combo scores ranging from 0.1016 to 3.6463\n",
      "36 feature combinations, with combo scores ranging from 0.1016 to 0.2017\n",
      "36 feature combinations, with combo scores ranging from 0.1016 to 0.2017\n"
     ]
    }
   ],
   "source": [
    "feature_combos_with_score_none, feature_combo_none, feature_combo_scores_none = jiaocheng.get_feature_combinations('Abs Corr', LABEL, 'None')\n",
    "feature_combos_with_score_mean, feature_combo_mean, feature_combo_scores_mean =jiaocheng.get_feature_combinations('Abs Corr', LABEL, 'Mean')\n",
    "feature_combos_with_score_max, feature_combo_max, feature_combo_scores_max =jiaocheng.get_feature_combinations('Abs Corr', LABEL, 'Max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combos = list()\n",
    "all_combos.extend(feature_combos_with_score_none)\n",
    "all_combos.extend(feature_combos_with_score_mean)\n",
    "all_combos.extend(feature_combos_with_score_max)\n",
    "len(all_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_duplicate_removal(feature_combos_with_score):\n",
    "        \"\"\" Helper function that remove duplicate combinations \"\"\"\n",
    "        for i in range(len(feature_combos_with_score)):\n",
    "            feature_combos_with_score[i][0].sort()\n",
    "\n",
    "        feature_combos_with_score.sort(key = lambda x:x[0])\n",
    "\n",
    "        duplicate_i = []\n",
    "\n",
    "        feature_combos_no_duplicates = []\n",
    "\n",
    "        for i in range(len(feature_combos_with_score)-1):\n",
    "            if i in duplicate_i:\n",
    "                continue\n",
    "\n",
    "            if feature_combos_with_score[i][0] == feature_combos_with_score[i+1][0]:\n",
    "                duplicate_i.append(i)\n",
    "            \n",
    "            if i not in duplicate_i:\n",
    "                feature_combos_no_duplicates.append(feature_combos_with_score[i])\n",
    "\n",
    "        return feature_combos_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos = features_duplicate_removal(all_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(f'../data/curated/modelling/{DATA_TYPE}_Train_{LABEL}.csv')\n",
    "val_data = pd.read_csv(f'../data/curated/modelling/{DATA_TYPE}_Validate_{LABEL}.csv')\n",
    "test_data = pd.read_csv(f'../data/curated/modelling/{DATA_TYPE}_Test_{LABEL}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.drop([LABEL], axis=1)\n",
    "train_y = train_data[LABEL]\n",
    "val_x = val_data.drop([LABEL], axis=1)\n",
    "val_y = val_data[LABEL]\n",
    "test_x = test_data.drop([LABEL], axis=1)\n",
    "test_y = test_data[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_df(model, x, y, combo):\n",
    "    pred_y = list((model.predict(x[combo])))\n",
    "\n",
    "    accu_df = pd.DataFrame({'pred': pred_y, 'y': list(y)})\n",
    "\n",
    "    accu_df['y_mean'] = np.mean(y)\n",
    "    \n",
    "    accu_df['TotErr'] = accu_df['y'] - accu_df['y_mean']\n",
    "    accu_df['TotSqErr'] = np.power(accu_df['TotErr'], 2)\n",
    "\n",
    "    accu_df['ResErr'] = accu_df['y'] - accu_df['pred']\n",
    "    accu_df['ResSqErr'] = np.power(accu_df['ResErr'], 2)\n",
    "\n",
    "    return accu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2(accu_df):\n",
    "\n",
    "    return 1 - sum(accu_df['ResSqErr'])/sum(accu_df['TotSqErr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_r2(accu_df, n, k):\n",
    "    \n",
    "    return 1-(sum(accu_df['ResSqErr'])/sum(accu_df['TotSqErr']))*((n-1)/(n-k-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_llh(accu_df, n):\n",
    "\n",
    "    llh = -(n/2)*np.log(sum(accu_df['ResSqErr'])/n)\n",
    "    \n",
    "    # sd_hat = sum(np.sqrt(accu_df['ResSqErr']))\n",
    "\n",
    "    # llh = -0.5*n * np.log(2*np.pi) - n * np.log(sd_hat) - (0.5*sd_hat) * sum(accu_df['ResSqErr'])\n",
    "\n",
    "    return llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aic(llh, k):\n",
    "\n",
    "    aic = 2*k - 2*llh\n",
    "    \n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bic(llh, n, k):\n",
    "\n",
    "    bic = (k+1)*np.log(n) - 2*llh\n",
    "    \n",
    "    return bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_result = pd.DataFrame()\n",
    "\n",
    "for combo in all_combos:\n",
    "\n",
    "    OLS_lm_fit = sm.OLS(train_y, train_x[combo[0]]).fit()\n",
    "\n",
    "\n",
    "    train_accu_df = get_accuracy_df(OLS_lm_fit, train_x, train_y, combo[0])\n",
    "    val_accu_df = get_accuracy_df(OLS_lm_fit, val_x, val_y, combo[0])\n",
    "    test_accu_df = get_accuracy_df(OLS_lm_fit, test_x, test_y, combo[0])\n",
    "    \n",
    "    n_train = len(train_accu_df)\n",
    "    n_val = len(val_accu_df)\n",
    "    n_test = len(test_accu_df)\n",
    "    k = len(combo)\n",
    "\n",
    "    train_r2 = get_r2(train_accu_df)\n",
    "    val_r2 = get_r2(val_accu_df)\n",
    "    test_r2 = get_r2(test_accu_df)\n",
    "\n",
    "    train_r2_adj = get_adj_r2(train_accu_df, n_train, k)\n",
    "    val_r2_adj = get_adj_r2(val_accu_df, n_val, k)\n",
    "    test_r2_adj = get_adj_r2(test_accu_df, n_test, k)\n",
    "\n",
    "    train_llh = get_norm_llh(train_accu_df, n_train)\n",
    "    val_llh = get_norm_llh(val_accu_df, n_val)\n",
    "    test_llh = get_norm_llh(test_accu_df, n_test)\n",
    "\n",
    "    train_aic = get_aic(train_llh, k)\n",
    "    val_aic = get_aic(val_llh, k)\n",
    "    test_aic = get_aic(test_llh, k)\n",
    "\n",
    "    train_bic = get_bic(train_llh, n_train, k)\n",
    "    val_bic = get_bic(val_llh, n_val, k)\n",
    "    test_bic = get_bic(test_llh, n_test, k)\n",
    "\n",
    "\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['combo'] = [combo[0]]\n",
    "    tmp['score'] = [combo[1]]\n",
    "\n",
    "    # tmp['Train r2'] = [OLS_lm_fit.rsquared]\n",
    "    tmp['Train r2'] = [train_r2]\n",
    "    tmp['Val r2'] = [val_r2]\n",
    "    tmp['Test r2'] = [test_r2]\n",
    "\n",
    "    # tmp['Train r2_adj'] = [OLS_lm_fit.rsquared_adj]\n",
    "    tmp['Train r2_adj'] = [train_r2_adj]\n",
    "    tmp['Val r2_adj'] = [val_r2_adj]\n",
    "    tmp['Test r2_adj'] = [test_r2_adj]\n",
    "\n",
    "    # tmp['Train AIC'] = [OLS_lm_fit.aic]\n",
    "    tmp['Train AIC'] = [train_aic]\n",
    "    tmp['Val AIC'] = [val_aic]\n",
    "    tmp['Test AIC'] = [test_aic]\n",
    "\n",
    "    # tmp['Train BIC'] = [OLS_lm_fit.bic]\n",
    "    tmp['Val BIC'] = [train_bic]\n",
    "    tmp['Val BIC'] = [val_bic]\n",
    "    tmp['Test BIC'] = [test_bic]\n",
    "\n",
    "    # tmp['Train llh'] = [OLS_lm_fit.llf]\n",
    "    tmp['Train llh'] = [train_llh]\n",
    "    tmp['Val llh'] = [val_llh]\n",
    "    tmp['Test llh'] = [test_llh]    \n",
    "\n",
    "    tuning_result = tuning_result.append(tmp)\n",
    "\n",
    "tuning_result.to_csv(f'../models/tuning/{DATA_TYPE}_lm_{LABEL}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
