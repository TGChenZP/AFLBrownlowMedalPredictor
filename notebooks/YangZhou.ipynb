{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as s\n",
    "import copy\n",
    "import time\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YangZhou:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('YangZhou Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.checked_core = None\n",
    "        self.been_best = None\n",
    "        self.been_cruised = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self.parameter_value_map_index = None\n",
    "        self._seed = 19260817\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.combos = None\n",
    "        self.n_items = None\n",
    "        self._core = None\n",
    "        self._cruise_indices = None\n",
    "        self._cruise_indices_values = None\n",
    "        self.cruise_combinations = None\n",
    "        self._restarts = 0\n",
    "        self._cruising = True\n",
    "        self._surrounding_vectors = None\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_data(self, train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.train_x = train_x\n",
    "        print(\"Read in Train X data\")\n",
    "\n",
    "        self.train_y = train_y\n",
    "        print(\"Read in Train x data\")\n",
    "\n",
    "        self.val_x = val_x\n",
    "        print(\"Read in Val X data\")\n",
    "\n",
    "        self.val_y = val_y\n",
    "        print(\"Read in Val y data\")\n",
    "\n",
    "        self.test_x = test_x\n",
    "        print(\"Read in Test X data\")\n",
    "\n",
    "        self.test_y = test_y\n",
    "        print(\"Read in Test y data\")\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self.sort_hyperparameter_choices()\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self.num_hyperparameters = {hyperparameter:len(parameter_choices[hyperparameter]) for hyperparameter in self.hyperparameters}\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        # self._get_combinations() ## TODO: discard\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "    \n",
    "    def sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "        self.checked_core = np.zeros(shape=self.n_items)\n",
    "        self.been_best = np.zeros(shape=self.n_items) # strictly for last part of Guidance Algorithm\n",
    "        self.been_cruised = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_combinations(self):\n",
    "\n",
    "        self._get_cruise_indices_values()\n",
    "        self._generate_cruise_combinations()\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_values(self):\n",
    "        \"\"\" get cruise indices values of each dimension which serves as building blocks for cruise combinations \"\"\"\n",
    "\n",
    "        self._cruise_indices = dict()\n",
    "        for hyperparameter in self.hyperparameters:\n",
    "            self._cruise_indices[hyperparameter] = self._get_cruise_indices_1d(d_val = self.num_hyperparameters[hyperparameter], max_jump = 5)\n",
    "\n",
    "        ##TODO: Can toggle with get_cruise_indices!!!! should add parameter to do so!!\n",
    "        self._cruise_indices_values = list(self._cruise_indices.values())\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_1d(self, d_val, max_jump = 5): ## TODO: max_jump\n",
    "        \"\"\" Returns the appropriate cruise indices based on the number of values in dimension. Second argument controls maximum split size, defaulted to 5 \"\"\"\n",
    "\n",
    "        assert type(d_val) is int and type(max_jump) is int, \"Error: type of input(s) is not int\"\n",
    "        assert d_val >= 2, \"Error: argument 1 (number of values in this dimension) must be >= 2\"\n",
    "        assert max_jump >= 1, \"Error: max_jump must be >= 1\"\n",
    "\n",
    "        gap = d_val - 1\n",
    "        split = ((gap-1)//max_jump)\n",
    "\n",
    "        jump = self._find_gaps(split, gap)\n",
    "\n",
    "        cruise_indices_1d = self._find_cruise_indices_1d(jump)\n",
    "\n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _find_gaps(self, split, gap):\n",
    "        \"\"\" find the size of jumps between each element of the final cruise indices, as evenly split as possible with jump size <= 5 \"\"\"\n",
    "\n",
    "        if split > 0:\n",
    "            jump = [gap//(split+1) for i in range(split+1)]\n",
    "            diff = gap - sum(jump)\n",
    "            if diff:\n",
    "                for i in range(diff):\n",
    "                    jump[i] += 1\n",
    "        else:\n",
    "            jump = [gap]\n",
    "\n",
    "        return jump\n",
    "\n",
    "\n",
    "\n",
    "    def _find_cruise_indices_1d(self, jump):\n",
    "        \"\"\" find the actual cruise_indices based on gaps \"\"\"\n",
    "\n",
    "        cruise_indices_1d = [0]\n",
    "        for i in range(len(jump)):\n",
    "            cruise_indices_1d.append(sum(jump[:i+1]))\n",
    "\n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _generate_cruise_combinations(self):\n",
    "        \n",
    "        self.cruise_combinations = [[]]\n",
    "        for i in range(len(self._cruise_indices_values)):\n",
    "\n",
    "            tmp = copy.deepcopy(self.cruise_combinations)\n",
    "            self.cruise_combinations = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in self._cruise_indices_values[i]:\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self.cruise_combinations.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_cruise_coordinates(self, max_combo):\n",
    "        \"\"\" sort the cruise coordinates based on distance from current max\"\"\"\n",
    "\n",
    "\n",
    "        edist = list(cdist([max_combo], self.cruise_combinations).flatten())\n",
    "        ordered_cruise_combos = [(self.cruise_combinations[i], edist[i]) for i in range(len(self.cruise_combinations))]\n",
    "\n",
    "        ordered_cruise_combos.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "        sorted_cruise_combos = [ordered_cruise_combos[i][0] for i in range(len(ordered_cruise_combos))]\n",
    "\n",
    "        return sorted_cruise_combos\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_max_surrounding_mean_sd(self):\n",
    "\n",
    "        best_combo_surrounding_combos = self._get_surrounding_coordinates(self.best_combo, self._surrounding_vectors)\n",
    "        best_combo_surrounding_scores = [self.best_score]\n",
    "        for combo in best_combo_surrounding_combos:\n",
    "            best_combo_surrounding_scores.append(self.result[tuple(combo)])\n",
    "\n",
    "        max_surrounding_sd = s.stdev(best_combo_surrounding_scores)\n",
    "\n",
    "        return max_surrounding_sd\n",
    "\n",
    "\n",
    "\n",
    "    def _cruise_warning_threshold(self, max_accuracy, max_surrounding_sd, max_surrounding_n):\n",
    "        \"\"\" max - halfwidth \"\"\"\n",
    "\n",
    "        # TO ADJUST: 0.95 to 0.975; \n",
    "        # TO ADJUST: max change to mean value\n",
    "        qt = t.ppf(0.95, max_surrounding_n-1) # One sided test\n",
    "        halfwidth = max_surrounding_sd * qt * 1/np.sqrt(max_surrounding_n)\n",
    "\n",
    "        return max_accuracy - halfwidth\n",
    "\n",
    "\n",
    "\n",
    "    def _CruiseSystem(self):\n",
    "\n",
    "        # print(f\"Cruising: round {self._restarts}\\n\") \n",
    "\n",
    "        # get cruise coordinates in sorted order (furthest away from current max)\n",
    "        sorted_cruise_coordinates = self._sort_cruise_coordinates(self.best_combo)\n",
    "            # 理论：如果往少train，则应该randomise，或者就近来train (更可能得早点把score刷高，不触发)\n",
    "\n",
    "        # calculate warning threshold\n",
    "        max_surrounding_sd = self._get_max_surrounding_mean_sd()\n",
    "\n",
    "\n",
    "        warning_threshold = self._cruise_warning_threshold(self.best_score, max_surrounding_sd, len(self._surrounding_vectors)-1)\n",
    "\n",
    "        # check each cruise coordinate\n",
    "        for cruise_combo in sorted_cruise_coordinates:\n",
    "\n",
    "            # only search if it hasn't been cruised before (if has then is not an artifect of significance)\n",
    "            if not self.been_cruised[tuple(cruise_combo)]:\n",
    "                \n",
    "                self.been_cruised[tuple(cruise_combo)] = 2\n",
    "\n",
    "                # if above warning threshold, then stop cruise and restart guide\n",
    "                if self.result[tuple(cruise_combo)] >= warning_threshold:\n",
    "                   \n",
    "                    # print(f\"Cruise suspended due to suspicious case\")\n",
    "                    \n",
    "                    return\n",
    "\n",
    "        # if reach here then all cruise indicies checked. can safely say end cruise\n",
    "        \n",
    "        self._cruising = False\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_surrounding_vectors(self, core):\n",
    "        \"\"\" Get the VECTORS that moves the core to the COORDINATES that form the 3^d object around it \"\"\"\n",
    "\n",
    "        values = [-1, 0, 1]\n",
    "        new_surroundings = [[-1], [0], [1]]\n",
    "\n",
    "        for i in range(len(core) - 1):\n",
    "            old_surroundings = copy.deepcopy(new_surroundings)\n",
    "            new_surroundings = list()\n",
    "\n",
    "            for surrounding in old_surroundings:\n",
    "                for value in values:\n",
    "                    new_surroundings.append(\n",
    "                        [surrounding[i] if i < len(surrounding) else value for i in range(len(surrounding) + 1)])\n",
    "\n",
    "        return new_surroundings\n",
    "\n",
    "\n",
    "\n",
    "    def _get_surrounding_coordinates(self, core, surrounding_vectors):\n",
    "        \"\"\" Use surrounding VECTORS to find surrounding COORDINATES \"\"\"\n",
    "        \n",
    "        # Note this surrounding vector is not the same as the static local object generated by _get_surrounding_vectors\n",
    "\n",
    "        assert len(surrounding_vectors) > 0\n",
    "        assert len(surrounding_vectors[0]) == len(core)\n",
    "\n",
    "        surrounding_coords = list()\n",
    "        for i in range(len(surrounding_vectors)):\n",
    "            new_coord = self._new_coordinates(core, surrounding_vectors[i])\n",
    "            if new_coord is not False:\n",
    "                surrounding_coords.append(new_coord)\n",
    "\n",
    "        return surrounding_coords\n",
    "\n",
    "\n",
    "\n",
    "    def _new_coordinates(self, core, vector):\n",
    "        \"\"\" Get particular COORDINATE using a move in direction of VECTOR from particular CORE \"\"\"\n",
    "\n",
    "        assert len(core) == len(vector)\n",
    "\n",
    "        new_coord = list()\n",
    "        for i in range(len(vector)):\n",
    "            val = core[i] + vector[i]\n",
    "            if val >= self.n_items[i] or val < 0:\n",
    "                return False\n",
    "            new_coord.append(val)\n",
    "\n",
    "        return new_coord\n",
    "\n",
    "\n",
    "\n",
    "    def _find_horizontal(self, surrounding_coordinates, core):\n",
    "        \"\"\" Find the treatment and nulls block from a 'Horizontal' vector move \"\"\"\n",
    "\n",
    "        treatment = list()\n",
    "        null = list()\n",
    "        direction = list()\n",
    "\n",
    "        for i in range(len(core)):\n",
    "\n",
    "            for move in [-1, 1]:\n",
    "                treatment_target = core[i] + move\n",
    "                null_target = core[i]\n",
    "\n",
    "                treatment_tmp = list()\n",
    "                null_tmp = list()\n",
    "\n",
    "                for vector in surrounding_coordinates:\n",
    "                    if vector[i] == treatment_target:\n",
    "                        treatment_tmp.append(vector)\n",
    "                    elif vector[i] == null_target:\n",
    "                        null_tmp.append(vector)\n",
    "\n",
    "                treatment.append(treatment_tmp)\n",
    "                null.append(null_tmp)\n",
    "                direction.append([move if j == i else 0 for j in range(len(core))])\n",
    "\n",
    "        return treatment, null, direction\n",
    "\n",
    "\n",
    "\n",
    "    def _pick_x(self, i, core):\n",
    "        \"\"\" Pick all combinations of range(len(core)) for indexing when getting diagonal treatments \"\"\"\n",
    "\n",
    "        return list(combinations(list(range(len(core))), i))\n",
    "\n",
    "\n",
    "\n",
    "    def get_indices(self, core):\n",
    "        \"\"\" Get combinations of index to be used to find diagonal treatments: part of special algorithm \"\"\"\n",
    "\n",
    "        indices = list()\n",
    "        for i in range(len(core)):\n",
    "            for obj in self._pick_x(i, core):\n",
    "                indices.append(obj)\n",
    "\n",
    "        return indices\n",
    "\n",
    "\n",
    "\n",
    "    def _find_diagonal(self, core, indices):\n",
    "        \"\"\" Find the treatment and nulls block from a 'Diagonal' vector move (effectively interaction of all params) \"\"\"\n",
    "\n",
    "        treatment = list()\n",
    "        null = list()\n",
    "\n",
    "        diagonals = self._get_diagonals()\n",
    "\n",
    "        for diagonal in diagonals:\n",
    "            treatment.append(self._get_diagonal_treatment(core, diagonal, indices))\n",
    "\n",
    "            null.append(self._get_diagonal_null(core, diagonal))\n",
    "\n",
    "        return treatment, null, diagonals\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diagonals(self):\n",
    "        \"\"\" Find all the diagonal vectors \"\"\"\n",
    "\n",
    "        return [obj for obj in self._surrounding_vectors if 0 not in obj]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diagonal_treatment(self, core, diagonal, indices):\n",
    "        \"\"\" Find all diagonal treatments of this diagonal direction - any vector that has from 1 to d elements in same\n",
    "        direction diagonal, and all other vector positions 0 \"\"\"\n",
    "        treatment = self._get_surrounding_coordinates(core, self._get_diag_treatment_vectors(indices, diagonal))\n",
    "\n",
    "        return treatment\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diag_treatment_vectors(self, indices, diagonal):\n",
    "        \"\"\" Find all vectors for diagonal treatments (orthogonal to direction or  0 vector) \"\"\"\n",
    "\n",
    "        diag_vectors = list()\n",
    "\n",
    "        for index in indices:\n",
    "            tmp = [0 for i in range(len(diagonal))]\n",
    "            for i in index:\n",
    "                tmp[i] = diagonal[i]\n",
    "            diag_vectors.append(tmp)\n",
    "\n",
    "        return diag_vectors\n",
    "\n",
    "\n",
    "\n",
    "    def _get_diagonal_null(self, core, diagonal):\n",
    "        \"\"\" Find all diagonal nulls of this diagonal direction - any vector that is orthogonal to the current direction \"\"\"\n",
    "\n",
    "        null = list()\n",
    "        for surrounding_vector in self._surrounding_vectors:\n",
    "            if np.dot(surrounding_vector, diagonal) == 0:\n",
    "                new_coord = self._new_coordinates(core, surrounding_vector)\n",
    "                if new_coord is not False:\n",
    "                    null.append(new_coord)\n",
    "\n",
    "        return null\n",
    "\n",
    "\n",
    "\n",
    "    def _get_blocks(self, core, surrounding_coordinates, indices):\n",
    "        \"\"\" Get all blocks' treatments and nulls (in respective lists) (both horizontal and diagonal) \"\"\"\n",
    "\n",
    "        treatment = list()\n",
    "        null = list()\n",
    "        direction = list()\n",
    "\n",
    "        hor_treatment, hor_null, hor_dir = self._find_horizontal(surrounding_coordinates, core)\n",
    "\n",
    "        diag_treatment, diag_null, vert_dir = self._find_diagonal(core, indices)\n",
    "\n",
    "        treatment.extend(hor_treatment)\n",
    "        treatment.extend(diag_treatment)\n",
    "\n",
    "        null.extend(hor_null)\n",
    "        null.extend(diag_null)\n",
    "\n",
    "        direction.extend(hor_dir)\n",
    "        direction.extend(vert_dir)\n",
    "\n",
    "        return treatment, null, direction\n",
    "\n",
    "\n",
    "\n",
    "    def _get_treat_or_null_tune_scores(self, treat_or_null):\n",
    "        \"\"\" Return as the relevant scores as a list to be used for t_test \"\"\"\n",
    "\n",
    "        treat_or_null_score = dict()\n",
    "\n",
    "        for combo in treat_or_null:\n",
    "            treat_or_null_score[tuple(combo)] = self.result[tuple(combo)]\n",
    "\n",
    "        return treat_or_null_score\n",
    "\n",
    "\n",
    "\n",
    "    def _dict_arg_max(self, dic):\n",
    "        \"\"\" find key of maximum dict value \"\"\"\n",
    "        \n",
    "        max_val = -np.inf\n",
    "        for key in dic:\n",
    "            if dic[key] > max_val:\n",
    "                max_val = dic[key]\n",
    "                max_key = key\n",
    "\n",
    "        return max_key\n",
    "\n",
    "\n",
    "\n",
    "    def _find_new_core(self, treatment, null, direction):\n",
    "        \"\"\" Only positive mean and < 0.05 \"\"\"\n",
    "\n",
    "        assert len(treatment) == len(null)\n",
    "        assert len(treatment) == len(direction)\n",
    "\n",
    "        new_cores = list()\n",
    "\n",
    "        for i in range(len(treatment)): # TODO: also record the p values, so we only accept those with lowerst p value - but may need to adjust bottom's 'checked_core'\n",
    "            if len(treatment[i]) <= 1 or len(null[i]) <= 1:\n",
    "                continue\n",
    "\n",
    "            bool_inc = np.mean(list(self._get_treat_or_null_tune_scores(treatment[i]).values())) > np.mean(\n",
    "                list(self._get_treat_or_null_tune_scores(null[i]).values()))\n",
    "            \n",
    "            if bool_inc:\n",
    "\n",
    "                p_val = stats.ttest_ind(list(self._get_treat_or_null_tune_scores(treatment[i]).values()),\n",
    "                                    list(self._get_treat_or_null_tune_scores(null[i]).values()),\n",
    "                                    equal_var=False).pvalue #TODO: True or False #尝试改one sided？\n",
    "\n",
    "                if p_val < 0.05:\n",
    "                    \n",
    "                    max_combo_of_treatment = self._dict_arg_max(self._get_treat_or_null_tune_scores(treatment[i]))\n",
    "\n",
    "                    if not self.checked_core[max_combo_of_treatment]:\n",
    "                        new_cores.append(max_combo_of_treatment)\n",
    "                        self.checked_core[max_combo_of_treatment] = 1\n",
    "\n",
    "        return new_cores\n",
    "\n",
    "\n",
    "\n",
    "    def _get_new_cores(self, core):\n",
    "\n",
    "        # if (should be rare) case where core has been a core before, then skip. For prevention of infinite loops\n",
    "        # 2 means actual checked core, 1 means appended to checked core list but not checked\n",
    "        if self.checked_core[tuple(core)] == 2:\n",
    "            return\n",
    "        else:\n",
    "            self.checked_core[tuple(core)] = 2\n",
    "            \n",
    "\n",
    "        # prepare data for welch test\n",
    "        surrounding_coordinates = self._get_surrounding_coordinates(core, self._surrounding_vectors)\n",
    "\n",
    "        indices = self.get_indices(core)\n",
    "\n",
    "        # put coordinates into treatments and nulls\n",
    "        treatment, null, direction = self._get_blocks(core, surrounding_coordinates, indices)\n",
    "\n",
    "        # actually tune the surrounding coordinates\n",
    "        for combo in surrounding_coordinates:\n",
    "            \n",
    "            if self.checked[tuple(combo)] == 0:\n",
    "                self._train_and_test_combo(combo)\n",
    "            # else:\n",
    "                # print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "\n",
    "        # perform welch test and return surrounding coordinates that should be used as new core\n",
    "        new_cores = self._find_new_core(treatment, null, direction)\n",
    "\n",
    "        return new_cores  \n",
    "\n",
    "\n",
    "\n",
    "    def _GuidanceSystem(self, core):\n",
    "\n",
    "        # if self._restarts == 0:\n",
    "        #     print(\"Guidance: initial round \\n\")\n",
    "        # else:\n",
    "        #     print(\"Guidance: round\", self._restarts, '\\n')\n",
    "\n",
    "        # print('\\tround', self._restarts, 'iteration: ', 0, '\\n')\n",
    "\n",
    "        # first get a surrounding 3^d tuned\n",
    "        new_cores = self._get_new_cores(core)\n",
    "        self.been_cruised[tuple(core)] == 1\n",
    "\n",
    "        round = 1\n",
    "        while new_cores: # while new cores are being added\n",
    "            # print('\\tround', self._restarts, \"iteration: \", round, \"\\n\") \n",
    "            round += 1\n",
    "\n",
    "            # print('New cores:', new_cores, '\\n')\n",
    "            old_new_cores = copy.deepcopy(new_cores)\n",
    "            new_cores = list()\n",
    "\n",
    "            # for each of the new cores, 'recursively' tune and grab new cores; but each Iteration doesn't end until all cores of current round has been checked\n",
    "            for new_core in old_new_cores:\n",
    "                \n",
    "                new_new_cores = self._get_new_cores(new_core)\n",
    "                self.been_cruised[tuple(core)] == 1\n",
    "                \n",
    "                for new_new_core in new_new_cores:\n",
    "                    if self.checked_core[tuple(new_new_core)] == 0:\n",
    "                        new_cores.append(new_new_core)\n",
    "                        self.checked_core[tuple(new_new_core)] = 1\n",
    "\n",
    "        # for current max, get 3^d block. if new max happens to be found, continue to do 3^d block until no new max is found\n",
    "        # just a cheap way to flesh out the max (the goal of YangZhou)\n",
    "\n",
    "        while self.been_best[tuple(self.best_combo)] == 0:\n",
    "\n",
    "            self.been_best[tuple(self.best_combo)] = 1\n",
    "            #add surrounding find!! ##functionalise\n",
    "            surrounding_coordinates = self._get_surrounding_coordinates(self.best_combo, self._surrounding_vectors)\n",
    "            for combo in surrounding_coordinates:\n",
    "                \n",
    "                if self.checked[tuple(combo)] == 0:\n",
    "                    self._train_and_test_combo(combo)\n",
    "                # else:\n",
    "                    # print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "\n",
    "        # print information of this round \n",
    "\n",
    "        # if len(self.hyperparameters) == 2:\n",
    "        #     print('Score: \\n', self.result.round(4), '\\n')\n",
    "        #     print('Checked Combos: \\n', self.checked.round(4), '\\n')\n",
    "\n",
    "        # print('Max Accuracy From This Guidance Round: \\n', self.best_score)\n",
    "        # print('Max Combo From This Guidance Round: \\n', self.best_combo)\n",
    "\n",
    "        # print('% Combos Checked Thus Far:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "        # # print('Best Combo Found Thus Far?', max_accuracy == max(synthetic_data))\n",
    "        # # print('Accuracy Diff Between Max Combo and Max Found Thus Far:', max(synthetic_data)-max_accuracy)\n",
    "        # print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    def tune(self):\n",
    "\n",
    "        # print(\"BEGIN TUNING\\n\\n\") \n",
    "        \n",
    "        self._get_core()\n",
    "        self._get_cruise_combinations() \n",
    "\n",
    "        first_round_combinations = copy.deepcopy(self.cruise_combinations)\n",
    "        first_round_combinations.append(self._core) \n",
    "\n",
    "        random.shuffle(first_round_combinations)\n",
    "\n",
    "        # First, tune all cruise combinations and initial core\n",
    "        # print(\"STAGE ZERO: Tune all Cruise combinations\\n\\n\")\n",
    "        for combo in first_round_combinations:\n",
    "            \n",
    "            if not self.checked[tuple(combo)]:\n",
    "                \n",
    "                self._train_and_test_combo(combo)\n",
    "            \n",
    "            # else:\n",
    "            #     print(f'\\tAlready Trained and Tested combination {combo}')\n",
    "        \n",
    "\n",
    "        self._surrounding_vectors = self._get_surrounding_vectors(self.best_combo)\n",
    "\n",
    "        # print('\\n')\n",
    "        # print(\"STAGE ONE: Begin initial Guidance system\\n\\n\")\n",
    "\n",
    "        self._restarts = 0\n",
    "        # Initial Round of Guidance\n",
    "        self.GuidanceSystem(self.best_combo)\n",
    "        self._restarts += 1\n",
    "\n",
    "        # Recursively Cruise and restart Guide if find a combo that is within halfwidth of max\n",
    "        # print(\"STAGE TWO: Begin Cruise system\\n\\n\")\n",
    "        self._cruising = True\n",
    "        while self._cruising:\n",
    "            self._CruiseSystem()\n",
    "\n",
    "            if self._cruising:\n",
    "                self.GuidanceSystem(self.best_combo)\n",
    "                self._restarts += 1\n",
    "\n",
    "        # Final extensive search around maxes.\n",
    "        # print(\"FINAL STAGE: Begin final Guidance system\\n\\n\")\n",
    "        old_best_score = copy.deepcopy(self.best_score)\n",
    "        self._restarts = 'FINAL'\n",
    "\n",
    "        self.GuidanceSystem(self.best_combo)\n",
    "\n",
    "        while(self.best_score-old_best_score > 0):\n",
    "            old_best_score = copy.deepcopy(self.best_score)\n",
    "            self.GuidanceSystem(self.best_combo)\n",
    "\n",
    "\n",
    "        # Display final information\n",
    "        # print(\"TUNING FINISHED\\n\")\n",
    "\n",
    "        # if len(self.hyperparameters) == 2:\n",
    "        #     print('Final Found: \\n', self.result.round(4), '\\n')\n",
    "        #     print('Final Checked Combos: \\n', self.checked.round(4), '\\n')\n",
    "        #     print('Final Checked Cores: \\n', self.checked_core.round(4), '\\n')\n",
    "\n",
    "        # print('Max Accuracy: \\n', self.best_score)\n",
    "        # print('Max Combo: \\n', self.best_combo)\n",
    "\n",
    "        # print('% Combos Checked:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "        # # print('Best Combo Found?', max_accuracy == max(synthetic_data))\n",
    "        # # print('Accuracy Diff Between Max Combo and Max Found:', max(synthetic_data)-max_accuracy)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # def _train_and_test_combo(self, combo):\n",
    "    #     \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "    #     combo = tuple(combo)\n",
    "        \n",
    "    #     params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "\n",
    "    #     # initialise object\n",
    "    #     clf = self.model(**params)\n",
    "\n",
    "    #     # get time and fit\n",
    "    #     start = time.time()\n",
    "    #     clf.fit(self.train_x, self.train_y)\n",
    "    #     end = time.time()\n",
    "\n",
    "    #     # get predicted labels/values for three datasets\n",
    "    #     train_pred = clf.predict(self.train_x)\n",
    "    #     val_pred = clf.predict(self.val_x)\n",
    "    #     test_pred = clf.predict(self.test_x)\n",
    "\n",
    "    #     # get scores and time used\n",
    "    #     time_used = end-start\n",
    "\n",
    "    #     # build output dictionary and save result\n",
    "    #     df_building_dict = params\n",
    "\n",
    "    #     if self.clf_type == 'Regression':\n",
    "    #         train_score = r2_score(self.train_y, train_pred)\n",
    "    #         val_score = r2_score(self.val_y, val_pred)\n",
    "    #         test_score = r2_score(self.test_y, test_pred)\n",
    "\n",
    "    #         train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "    #         val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "    #         test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "\n",
    "    #         train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "    #         val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "    #         test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "\n",
    "    #         df_building_dict['Train r2'] = [np.round(train_score, 4)]\n",
    "    #         df_building_dict['Val r2'] = [np.round(val_score, 4)]\n",
    "    #         df_building_dict['Test r2'] = [np.round(test_score, 4)]\n",
    "    #         df_building_dict['Train RMSE'] = [np.round(train_rmse, 4)]\n",
    "    #         df_building_dict['Val RMSE'] = [np.round(val_rmse, 4)]\n",
    "    #         df_building_dict['Test RMSE'] = [np.round(test_rmse, 4)]\n",
    "    #         df_building_dict['Train MAPE'] = [np.round(train_mape, 4)]\n",
    "    #         df_building_dict['Val MAPE'] = [np.round(val_mape, 4)]\n",
    "    #         df_building_dict['Test MAPE'] = [np.round(test_mape, 4)]\n",
    "    #         df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "        \n",
    "    #     elif self.clf_type == 'Classification':\n",
    "    #         train_score = accuracy_score(self.train_y, train_pred)\n",
    "    #         val_score = clf.score(self.val_y, val_pred)\n",
    "    #         test_score = clf.score(self.test_y, test_pred)\n",
    "\n",
    "    #         train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "    #         val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "    #         test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "\n",
    "    #         train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "    #         val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "    #         test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "\n",
    "    #         train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "    #         val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "    #         test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "        \n",
    "    #         train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "    #         val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "    #         test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "\n",
    "    #         df_building_dict['Train accu'] = [np.round(train_score, 4)]\n",
    "    #         df_building_dict['Val accu'] = [np.round(val_score, 4)]\n",
    "    #         df_building_dict['Test accu'] = [np.round(test_score, 4)]\n",
    "    #         df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 4)]\n",
    "    #         df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 4)]\n",
    "    #         df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 4)]\n",
    "    #         df_building_dict['Train f1'] = [np.round(train_f1, 4)]\n",
    "    #         df_building_dict['Val f1'] = [np.round(val_f1, 4)]\n",
    "    #         df_building_dict['Test f1'] = [np.round(test_f1, 4)]\n",
    "    #         df_building_dict['Train precision'] = [np.round(train_precision, 4)]\n",
    "    #         df_building_dict['Val precision'] = [np.round(val_precision, 4)]\n",
    "    #         df_building_dict['Test precision'] = [np.round(test_precision, 4)]\n",
    "    #         df_building_dict['Train recall'] = [np.round(train_recall, 4)]\n",
    "    #         df_building_dict['Val recall'] = [np.round(val_recall, 4)]\n",
    "    #         df_building_dict['Test recall'] = [np.round(test_recall, 4)]\n",
    "    #         df_building_dict['Time'] = [np.round(time_used, 2)]\n",
    "\n",
    "    #     tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "    #     self.tuning_result = self.tuning_result.append(tmp)\n",
    "    #     self._save_tuning_result()\n",
    "\n",
    "    #     # update best score stats\n",
    "    #     if val_score > self.best_score: \n",
    "    #         self.best_score = val_score\n",
    "    #         self.best_clf = clf\n",
    "    #         self.best_combo = combo\n",
    "\n",
    "    #     # update internal governing DataFrames\n",
    "    #     self.checked[combo] = 1\n",
    "    #     self.result[combo] = val_score\n",
    "\n",
    "    #     print('\\tTrained and Tested a Combo')\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        val_score = self.synth_data[combo]\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "        # print('\\tTrained and Tested a Combo')\n",
    "\n",
    "\n",
    "\n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        self.tuning_result.to_csv(f'{self.tuning_result_saving_address}.csv', index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print(f'(Current) Best combo: {self.best_combo} with val score {self.best_score}')\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            print(\"Missing parameter_choices to build parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            print('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of YangZhou\n",
    "        for row in self.tuning_result.iterrows():\n",
    "    \n",
    "            combo = tuple([self.parameter_value_map_index[hyperparam][row[1][hyperparam]] for hyperparam in self.hyperparameters])\n",
    "            \n",
    "            self.checked[combo] = 1\n",
    "            \n",
    "            if self.clf_type == 'Regression':\n",
    "                self.result[combo] = row[1]['Val r2']\n",
    "            elif self.clf_type == 'Classification':\n",
    "                self.result[combo] = row[1]['Val accu']\n",
    "        \n",
    "            # update best score stats\n",
    "            if self.result[combo] > self.best_score: \n",
    "                self.best_score = self.result[combo]\n",
    "                self.best_clf = None\n",
    "                print(f\"As new Best Combo {combo} is read in, best_clf is set to None\")\n",
    "                self.best_combo = combo\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self.parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self.parameter_value_map_index[key] = tmp\n",
    "\n",
    "\n",
    "    \n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "\n",
    "    def _set_object_saving_address(self, address):\n",
    "        \"\"\" Read in where to save the YangZhou object \"\"\"\n",
    "\n",
    "        self.object_saving_address = address\n",
    "        print('Successfully set object output address')\n",
    "\n",
    "\n",
    "\n",
    "    def export_yangzhou(self, address):\n",
    "        \"\"\" Export yangzhou object \"\"\"\n",
    "\n",
    "        self._set_object_saving_address(address)\n",
    "\n",
    "        # copy object and set big objects to None\n",
    "        object_save = copy.deepcopy(self)\n",
    "        \n",
    "        object_save.train_x = None\n",
    "        object_save.train_y = None\n",
    "        object_save.val_x = None\n",
    "        object_save.val_y = None\n",
    "        object_save.test_x = None\n",
    "        object_save.test_y = None\n",
    "\n",
    "        # Export\n",
    "        with open(f'{self.object_saving_address}.pickle', 'wb') as f:\n",
    "            pickle.dump(object_save, f)\n",
    "\n",
    "        print(f'Successfully exported YangZhou object as {self.object_saving_address}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-0.01, 0, -0.01, -0.02, -0.03]\n",
    "y = [-0.01, 0, -0.01, -0.02, -0.03, -0.02, -0.01]\n",
    "# z = [-0.01, 0, -0.01, -0.02, -0.03, -0.02, -0.01]\n",
    "# a = [-0.01, 0, -0.01, -0.02, -0.03, -0.02, -0.01]\n",
    "# b = [-0.01, 0, -0.01, -0.02, -0.03, -0.02, -0.01]\n",
    "\n",
    "synth_data = np.zeros([len(x),len(y)])\n",
    "\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "\n",
    "        synth_data[(i, j)] = 0.5+x[i]+y[j]+np.random.normal(0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4811, 0.4908, 0.4789, 0.4696, 0.4604, 0.4717, 0.4805],\n",
       "       [0.4923, 0.5001, 0.4904, 0.4802, 0.4691, 0.4786, 0.4918],\n",
       "       [0.4795, 0.4911, 0.482 , 0.4695, 0.461 , 0.4699, 0.4797],\n",
       "       [0.47  , 0.4802, 0.4701, 0.4593, 0.4501, 0.4604, 0.4701],\n",
       "       [0.4602, 0.4705, 0.4603, 0.4502, 0.4405, 0.452 , 0.4615]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_data.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_choices = {\n",
    "    'a': (0, 1, 2, 3, 4),\n",
    "    'b': (0, 1, 2, 3, 4, 5, 6),\n",
    "    # 'c': (0, 1, 2, 3, 4, 5, 6),\n",
    "    # 'd': (0, 1, 2, 3, 4, 5, 6),\n",
    "    # 'e': (0, 1, 2, 3, 4, 5, 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YangZhou Initialised\n"
     ]
    }
   ],
   "source": [
    "yangzhou = YangZhou()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully recorded hyperparameter choices\n"
     ]
    }
   ],
   "source": [
    "yangzhou.set_hyperparameters(parameter_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001089367134187"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(synth_data.reshape(np.prod(yangzhou.n_items,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "yangzhou.synth_data = synth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN TUNING\n",
      "\n",
      "\n",
      "STAGE ZERO: Tune all Cruise combinations\n",
      "\n",
      "\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\n",
      "\n",
      "STAGE ONE: Begin initial Guidance system\n",
      "\n",
      "\n",
      "Guidance: initial round \n",
      "\n",
      "\tround 0 iteration:  0 \n",
      "\n",
      "\tAlready Trained and Tested combination [0, 0]\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tAlready Trained and Tested combination [0, 0]\n",
      "\tAlready Trained and Tested combination [0, 1]\n",
      "\tTrained and Tested a Combo\n",
      "\tAlready Trained and Tested combination [1, 0]\n",
      "\tAlready Trained and Tested combination [1, 1]\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "\tTrained and Tested a Combo\n",
      "Score: \n",
      " [[0.4811 0.4908 0.4789 0.4696 0.     0.     0.4805]\n",
      " [0.4923 0.5001 0.4904 0.     0.     0.     0.    ]\n",
      " [0.4795 0.4911 0.482  0.4695 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.4602 0.     0.     0.4502 0.     0.     0.4615]] \n",
      "\n",
      "Checked Combos: \n",
      " [[1. 1. 1. 1. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 1.]] \n",
      "\n",
      "Max Accuracy From This Guidance Round: \n",
      " 0.5001089367134187\n",
      "Max Combo From This Guidance Round: \n",
      " (1, 1)\n",
      "% Combos Checked Thus Far: 15 out of 35 which is 42.857143%\n",
      "\n",
      "\n",
      "STAGE TWO: Begin Cruise system\n",
      "\n",
      "\n",
      "Cruising: round 1\n",
      "\n",
      "FINAL STAGE: Begin final Guidance system\n",
      "\n",
      "\n",
      "Guidance: round FINAL \n",
      "\n",
      "\tround FINAL iteration:  0 \n",
      "\n",
      "\tAlready Trained and Tested combination [0, 0]\n",
      "\tAlready Trained and Tested combination [0, 1]\n",
      "\tAlready Trained and Tested combination [0, 2]\n",
      "\tAlready Trained and Tested combination [1, 0]\n",
      "\tAlready Trained and Tested combination [1, 1]\n",
      "\tAlready Trained and Tested combination [1, 2]\n",
      "\tAlready Trained and Tested combination [2, 0]\n",
      "\tAlready Trained and Tested combination [2, 1]\n",
      "\tAlready Trained and Tested combination [2, 2]\n",
      "Score: \n",
      " [[0.4811 0.4908 0.4789 0.4696 0.     0.     0.4805]\n",
      " [0.4923 0.5001 0.4904 0.     0.     0.     0.    ]\n",
      " [0.4795 0.4911 0.482  0.4695 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.4602 0.     0.     0.4502 0.     0.     0.4615]] \n",
      "\n",
      "Checked Combos: \n",
      " [[1. 1. 1. 1. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 1.]] \n",
      "\n",
      "Max Accuracy From This Guidance Round: \n",
      " 0.5001089367134187\n",
      "Max Combo From This Guidance Round: \n",
      " (1, 1)\n",
      "% Combos Checked Thus Far: 15 out of 35 which is 42.857143%\n",
      "\n",
      "\n",
      "TUNING FINISHED\n",
      "\n",
      "Final Found: \n",
      " [[0.4811 0.4908 0.4789 0.4696 0.     0.     0.4805]\n",
      " [0.4923 0.5001 0.4904 0.     0.     0.     0.    ]\n",
      " [0.4795 0.4911 0.482  0.4695 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.4602 0.     0.     0.4502 0.     0.     0.4615]] \n",
      "\n",
      "Final Checked Combos: \n",
      " [[1. 1. 1. 1. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 1.]] \n",
      "\n",
      "Final Checked Cores: \n",
      " [[2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "Max Accuracy: \n",
      " 0.5001089367134187\n",
      "Max Combo: \n",
      " (1, 1)\n",
      "% Combos Checked: 15 out of 35 which is 42.857143%\n"
     ]
    }
   ],
   "source": [
    "yangzhou.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 0., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yangzhou.checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48  , 0.    , 0.    , 0.4692, 0.    , 0.    , 0.4798],\n",
       "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.47  , 0.    , 0.    , 0.4602, 0.    , 0.    , 0.4712],\n",
       "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , 0.    , 0.    , 0.46  , 0.4707],\n",
       "       [0.4791, 0.    , 0.    , 0.4691, 0.    , 0.4696, 0.4806]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yangzhou.result.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yangzhou.been_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yangzhou.been_cruised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yangzhou.checked.reshape((np.prod(yangzhou.n_items))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
